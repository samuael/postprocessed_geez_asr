{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qUVM5DEtUt5",
        "outputId": "ae7566a8-e260-435e-bc8f-5274b7e53e00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMfvbptApOp3",
        "outputId": "ae52cf9f-5402-4463-ef0a-38e75aeb3088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYDQCo7YKDiH"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import shutil\n",
        "import math\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "import codecs\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from random import shuffle\n",
        "from itertools import groupby\n",
        "from google.colab import drive\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4lksNO1KX11"
      },
      "outputs": [],
      "source": [
        "#@title Multi Head Attention\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, n_heads, d_queries, d_values, dropout, in_decoder=False):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_queries = d_queries\n",
        "        self.d_values = d_values\n",
        "        self.d_keys = d_queries\n",
        "        self.in_decoder = in_decoder\n",
        "\n",
        "        self.cast_queries = nn.Linear(d_model, n_heads * d_queries)\n",
        "        self.cast_keys_values = nn.Linear(d_model, n_heads * (d_queries + d_values))\n",
        "        self.cast_output = nn.Linear(n_heads * d_values, d_model)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.apply_dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query_sequences, key_value_sequences, key_value_sequence_lengths):\n",
        "        batch_size = query_sequences.size(0)  # batch size (N) in number of sequences\n",
        "        query_sequence_pad_length = query_sequences.size(1)\n",
        "        key_value_sequence_pad_length = key_value_sequences.size(1)\n",
        "        self_attention = torch.equal(key_value_sequences, query_sequences)\n",
        "        input_to_add = query_sequences.clone()\n",
        "        query_sequences = self.layer_norm(query_sequences)  # (N, query_sequence_pad_length, d_model)\n",
        "        if self_attention:\n",
        "            key_value_sequences = self.layer_norm(key_value_sequences)  # (N, key_value_sequence_pad_length, d_model)\n",
        "\n",
        "        # Project input sequences to queries, keys, values\n",
        "        queries = self.cast_queries(query_sequences)  # (N, query_sequence_pad_length, n_heads * d_queries)\n",
        "        keys, values = self.cast_keys_values(key_value_sequences).split(split_size=self.n_heads * self.d_keys, dim=-1)  # (N, key_value_sequence_pad_length, n_heads * d_keys), (N, key_value_sequence_pad_length, n_heads * d_values)\n",
        "\n",
        "        # Split the last dimension by the n_heads subspaces\n",
        "        queries = queries.contiguous().view(batch_size, query_sequence_pad_length, self.n_heads, self.d_queries)  # (N, query_sequence_pad_length, n_heads, d_queries)\n",
        "        keys = keys.contiguous().view(batch_size, key_value_sequence_pad_length, self.n_heads, self.d_keys)  # (N, key_value_sequence_pad_length, n_heads, d_keys)\n",
        "        values = values.contiguous().view(batch_size, key_value_sequence_pad_length, self.n_heads, self.d_values)  # (N, key_value_sequence_pad_length, n_heads, d_values)\n",
        "        queries = queries.permute(0, 2, 1, 3).contiguous().view(-1, query_sequence_pad_length, self.d_queries)  # (N * n_heads, query_sequence_pad_length, d_queries)\n",
        "        keys = keys.permute(0, 2, 1, 3).contiguous().view(-1, key_value_sequence_pad_length, self.d_keys)  # (N * n_heads, key_value_sequence_pad_length, d_keys)\n",
        "        values = values.permute(0, 2, 1, 3).contiguous().view(-1, key_value_sequence_pad_length, self.d_values)  # (N * n_heads, key_value_sequence_pad_length, d_values)\n",
        "\n",
        "        # Perform multi-head attention\n",
        "\n",
        "        # Perform dot-products\n",
        "        attention_weights = torch.bmm(queries, keys.permute(0, 2,\n",
        "                                                            1))  # (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "\n",
        "        # Scale dot-products\n",
        "        attention_weights = (1. / math.sqrt(\n",
        "            self.d_keys)) * attention_weights  # (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "\n",
        "        # Before computing softmax weights, prevent queries from attending to certain keys\n",
        "\n",
        "        # MASK 1: keys that are pads\n",
        "        not_pad_in_keys = torch.LongTensor(range(key_value_sequence_pad_length)).unsqueeze(0).unsqueeze(0).expand_as(\n",
        "            attention_weights).to(device)  # (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "        not_pad_in_keys = not_pad_in_keys < key_value_sequence_lengths.repeat_interleave(self.n_heads).unsqueeze(\n",
        "            1).unsqueeze(2).expand_as(\n",
        "            attention_weights)  # (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "        # Note: PyTorch auto-broadcasts singleton dimensions in comparison operations (as well as arithmetic operations)\n",
        "\n",
        "        # Mask away by setting such weights to a large negative number, so that they evaluate to 0 under the softmax\n",
        "        attention_weights = attention_weights.masked_fill(~not_pad_in_keys, -float('inf'))  # (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "\n",
        "        # MASK 2: if this is self-attention in the decoder, keys chronologically ahead of queries\n",
        "        if self.in_decoder and self_attention:\n",
        "            # Therefore, a position [n, i, j] is valid only if j <= i\n",
        "            # torch.tril(), i.e. lower triangle in a 2D matrix, sets j > i to 0\n",
        "            not_future_mask = torch.ones_like(\n",
        "                attention_weights).tril().bool().to(\n",
        "                device)  # (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "            # Mask away by setting such weights to a large negative number, so that they evaluate to 0 under the softmax\n",
        "            attention_weights = attention_weights.masked_fill(~not_future_mask, -float('inf'))  # (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "        # Compute softmax along the key dimension\n",
        "        attention_weights = self.softmax(\n",
        "            attention_weights)  # (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "        # Apply dropout\n",
        "        attention_weights = self.apply_dropout(\n",
        "            attention_weights)  # (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "        # Calculate sequences as the weighted sums of values based on these softmax weights\n",
        "        sequences = torch.bmm(attention_weights, values)  # (N * n_heads, query_sequence_pad_length, d_values)\n",
        "        # Unmerge batch and n_heads dimensions and restore original order of axes\n",
        "        sequences = sequences.contiguous().view(batch_size, self.n_heads, query_sequence_pad_length, self.d_values).permute(0, 2, 1,\n",
        "                                                                       3)  # (N, query_sequence_pad_length, n_heads, d_values)\n",
        "        # Concatenate the n_heads subspaces (each with an output of size d_values)\n",
        "        sequences = sequences.contiguous().view(batch_size, query_sequence_pad_length, -1)  # (N, query_sequence_pad_length, n_heads * d_values)\n",
        "        # Transform the concatenated subspace-sequences into a single output of size d_model\n",
        "        sequences = self.cast_output(sequences)  # (N, query_sequence_pad_length, d_model)\n",
        "        # Apply dropout and residual connection\n",
        "        sequences = self.apply_dropout(sequences) + input_to_add  # (N, query_sequence_pad_length, d_model)\n",
        "        return sequences\n",
        "\n",
        "\n",
        "class PositionWiseFCNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    The Position-Wise Feed Forward Network sublayer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_inner, dropout):\n",
        "        super(PositionWiseFCNetwork, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_inner = d_inner\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.fc1 = nn.Linear(d_model, d_inner)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(d_inner, d_model)\n",
        "        self.apply_dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, sequences):\n",
        "        \"\"\"\n",
        "        Forward prop.\n",
        "\n",
        "        :param sequences: input sequences, a tensor of size (N, pad_length, d_model)\n",
        "        :return: transformed output sequences, a tensor of size (N, pad_length, d_model)\n",
        "        \"\"\"\n",
        "        input_to_add = sequences.clone()  # (N, pad_length, d_model)\n",
        "        sequences = self.layer_norm(sequences)  # (N, pad_length, d_model)\n",
        "        sequences = self.apply_dropout(self.relu(self.fc1(sequences)))  # (N, pad_length, d_inner)\n",
        "        sequences = self.fc2(sequences)  # (N, pad_length, d_model)\n",
        "        sequences = self.apply_dropout(sequences) + input_to_add  # (N, pad_length, d_model)\n",
        "        return sequences\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The Encoder.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, positional_encoding, d_model, n_heads, d_queries, d_values, d_inner, n_layers,\n",
        "                 dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.positional_encoding = positional_encoding\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_queries = d_queries\n",
        "        self.d_values = d_values\n",
        "        self.d_inner = d_inner\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding.requires_grad = False\n",
        "        self.encoder_layers = nn.ModuleList([self.make_encoder_layer() for i in range(n_layers)])\n",
        "        self.apply_dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def make_encoder_layer(self):\n",
        "        encoder_layer = nn.ModuleList([MultiHeadAttention(d_model=self.d_model,\n",
        "                                                          n_heads=self.n_heads,\n",
        "                                                          d_queries=self.d_queries,\n",
        "                                                          d_values=self.d_values,\n",
        "                                                          dropout=self.dropout,\n",
        "                                                          in_decoder=False),\n",
        "                                       PositionWiseFCNetwork(d_model=self.d_model,\n",
        "                                                             d_inner=self.d_inner,\n",
        "                                                             dropout=self.dropout)])\n",
        "\n",
        "        return encoder_layer\n",
        "\n",
        "\n",
        "    def forward(self, encoder_sequences, encoder_sequence_lengths):\n",
        "        pad_length = encoder_sequences.size(1)\n",
        "        encoder_sequences = self.embedding(encoder_sequences) * math.sqrt(self.d_model) + self.positional_encoding[:,\n",
        "                                                                                          :pad_length, :].to(\n",
        "            device)  # (N, pad_length, d_model)\n",
        "        encoder_sequences = self.apply_dropout(encoder_sequences)  # (N, pad_length, d_model)\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            encoder_sequences = encoder_layer[0](query_sequences=encoder_sequences,\n",
        "                                                 key_value_sequences=encoder_sequences,\n",
        "                                                 key_value_sequence_lengths=encoder_sequence_lengths)  # (N, pad_length, d_model)\n",
        "            encoder_sequences = encoder_layer[1](sequences=encoder_sequences)  # (N, pad_length, d_model)\n",
        "        encoder_sequences = self.layer_norm(encoder_sequences)  # (N, pad_length, d_model)\n",
        "\n",
        "        return encoder_sequences\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, positional_encoding, d_model, n_heads, d_queries, d_values, d_inner, n_layers, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.positional_encoding = positional_encoding\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_queries = d_queries\n",
        "        self.d_values = d_values\n",
        "        self.d_inner = d_inner\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding.requires_grad = False\n",
        "        self.decoder_layers = nn.ModuleList([self.make_decoder_layer() for i in range(n_layers)])\n",
        "        self.apply_dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def make_decoder_layer(self):\n",
        "        decoder_layer = nn.ModuleList([MultiHeadAttention(d_model=self.d_model,\n",
        "                                                          n_heads=self.n_heads,\n",
        "                                                          d_queries=self.d_queries,\n",
        "                                                          d_values=self.d_values,\n",
        "                                                          dropout=self.dropout,\n",
        "                                                          in_decoder=True),\n",
        "                                       MultiHeadAttention(d_model=self.d_model,\n",
        "                                                          n_heads=self.n_heads,\n",
        "                                                          d_queries=self.d_queries,\n",
        "                                                          d_values=self.d_values,\n",
        "                                                          dropout=self.dropout,\n",
        "                                                          in_decoder=True),\n",
        "                                       PositionWiseFCNetwork(d_model=self.d_model,\n",
        "                                                             d_inner=self.d_inner,\n",
        "                                                             dropout=self.dropout)])\n",
        "\n",
        "        return decoder_layer\n",
        "\n",
        "    def forward(self, decoder_sequences, decoder_sequence_lengths, encoder_sequences, encoder_sequence_lengths):\n",
        "        \"\"\"\n",
        "        Forward prop.\n",
        "\n",
        "        :param decoder_sequences: the source language sequences, a tensor of size (N, pad_length)\n",
        "        :param decoder_sequence_lengths: true lengths of these sequences, a tensor of size (N)\n",
        "        :param encoder_sequences: encoded source language sequences, a tensor of size (N, encoder_pad_length, d_model)\n",
        "        :param encoder_sequence_lengths: true lengths of these sequences, a tensor of size (N)\n",
        "        :return: decoded target language sequences, a tensor of size (N, pad_length, vocab_size)\n",
        "        \"\"\"\n",
        "        pad_length = decoder_sequences.size(1)  # pad-length of this batch only, varies across batches\n",
        "\n",
        "        # Sum vocab embeddings and position embeddings\n",
        "        # print(\"d_model: \", self.d_model, \"Embedding: \", len(self.embedding(decoder_sequences)), len(self.positional_encoding) , pad_length)#[:,\n",
        "                                                                                          #:pad_length, :])),\n",
        "        decoder_sequences = self.embedding(decoder_sequences) * math.sqrt(self.d_model) + self.positional_encoding[:,\n",
        "                                                                                          :pad_length, :].to(\n",
        "            device)  # (N, pad_length, d_model)\n",
        "\n",
        "        # Dropout\n",
        "        decoder_sequences = self.apply_dropout(decoder_sequences)\n",
        "\n",
        "        # Decoder layers\n",
        "        for decoder_layer in self.decoder_layers:\n",
        "            # Sublayers\n",
        "            decoder_sequences = decoder_layer[0](query_sequences=decoder_sequences,\n",
        "                                                 key_value_sequences=decoder_sequences,\n",
        "                                                 key_value_sequence_lengths=decoder_sequence_lengths)  # (N, pad_length, d_model)\n",
        "            decoder_sequences = decoder_layer[1](query_sequences=decoder_sequences,\n",
        "                                                 key_value_sequences=encoder_sequences,\n",
        "                                                 key_value_sequence_lengths=encoder_sequence_lengths)  # (N, pad_length, d_model)\n",
        "            decoder_sequences = decoder_layer[2](sequences=decoder_sequences)  # (N, pad_length, d_model)\n",
        "\n",
        "        # Apply layer-norm\n",
        "        decoder_sequences = self.layer_norm(decoder_sequences)  # (N, pad_length, d_model)\n",
        "\n",
        "        # Find logits over vocabulary\n",
        "        decoder_sequences = self.fc(decoder_sequences)  # (N, pad_length, vocab_size)\n",
        "\n",
        "        return decoder_sequences\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    The Transformer network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, positional_encoding, d_model=512, n_heads=16, d_queries=64, d_values=64,\n",
        "                 d_inner=2048, n_layers=6, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param vocab_size: size of the (shared) vocabulary\n",
        "        :param positional_encoding: positional encodings up to the maximum possible pad-length\n",
        "        :param d_model: size of vectors throughout the transformer model\n",
        "        :param n_heads: number of heads in the multi-head attention\n",
        "        :param d_queries: size of query vectors (and also the size of the key vectors) in the multi-head attention\n",
        "        :param d_values: size of value vectors in the multi-head attention\n",
        "        :param d_inner: an intermediate size in the position-wise FC\n",
        "        :param n_layers: number of layers in the Encoder and Decoder\n",
        "        :param dropout: dropout probability\n",
        "        \"\"\"\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.positional_encoding = positional_encoding\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_queries = d_queries\n",
        "        self.d_values = d_values\n",
        "        self.d_inner = d_inner\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.encoder = Encoder(vocab_size=vocab_size,\n",
        "                               positional_encoding=positional_encoding,\n",
        "                               d_model=d_model,\n",
        "                               n_heads=n_heads,\n",
        "                               d_queries=d_queries,\n",
        "                               d_values=d_values,\n",
        "                               d_inner=d_inner,\n",
        "                               n_layers=n_layers,\n",
        "                               dropout=dropout)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(vocab_size=vocab_size,\n",
        "                               positional_encoding=positional_encoding,\n",
        "                               d_model=d_model,\n",
        "                               n_heads=n_heads,\n",
        "                               d_queries=d_queries,\n",
        "                               d_values=d_values,\n",
        "                               d_inner=d_inner,\n",
        "                               n_layers=n_layers,\n",
        "                               dropout=dropout)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"\n",
        "        Initialize weights in the transformer model.\n",
        "        \"\"\"\n",
        "        # Glorot uniform initialization with a gain of 1.\n",
        "        for p in self.parameters():\n",
        "            # Glorot initialization needs at least two dimensions on the tensor\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p, gain=1.)\n",
        "\n",
        "        # Share weights between the embedding layers and the logit layer\n",
        "        nn.init.normal_(self.encoder.embedding.weight, mean=0., std=math.pow(self.d_model, -0.5))\n",
        "        self.decoder.embedding.weight = self.encoder.embedding.weight\n",
        "        self.decoder.fc.weight = self.decoder.embedding.weight\n",
        "\n",
        "        print(\"Model initialized.\")\n",
        "\n",
        "    def forward(self, encoder_sequences, decoder_sequences, encoder_sequence_lengths, decoder_sequence_lengths):\n",
        "        \"\"\"\n",
        "        Forward propagation.\n",
        "\n",
        "        :param encoder_sequences: source language sequences, a tensor of size (N, encoder_sequence_pad_length)\n",
        "        :param decoder_sequences: target language sequences, a tensor of size (N, decoder_sequence_pad_length)\n",
        "        :param encoder_sequence_lengths: true lengths of source language sequences, a tensor of size (N)\n",
        "        :param decoder_sequence_lengths: true lengths of target language sequences, a tensor of size (N)\n",
        "        :return: decoded target language sequences, a tensor of size (N, decoder_sequence_pad_length, vocab_size)\n",
        "        \"\"\"\n",
        "        # Encoder\n",
        "        encoder_sequences = self.encoder(encoder_sequences,\n",
        "                                         encoder_sequence_lengths)  # (N, encoder_sequence_pad_length, d_model)\n",
        "\n",
        "        # Decoder\n",
        "        decoder_sequences = self.decoder(decoder_sequences, decoder_sequence_lengths, encoder_sequences,\n",
        "                                         encoder_sequence_lengths)  # (N, decoder_sequence_pad_length, vocab_size)\n",
        "\n",
        "        return decoder_sequences\n",
        "\n",
        "\n",
        "class LabelSmoothedCE(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, eps=0.1):\n",
        "        \"\"\"\n",
        "        :param eps: smoothing co-efficient\n",
        "        \"\"\"\n",
        "        super(LabelSmoothedCE, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, inputs, targets, lengths):\n",
        "        \"\"\"\n",
        "        Forward prop.\n",
        "\n",
        "        :param inputs: decoded target language sequences, a tensor of size (N, pad_length, vocab_size)\n",
        "        :param targets: gold target language sequences, a tensor of size (N, pad_length)\n",
        "        :param lengths: true lengths of these sequences, to be able to ignore pads, a tensor of size (N)\n",
        "        :return: mean label-smoothed cross-entropy loss, a scalar\n",
        "        \"\"\"\n",
        "        # Remove pad-positions and flatten\n",
        "        inputs, _, _, _ = pack_padded_sequence(input=inputs, lengths=lengths.to(\"cpu\"), batch_first=True, enforce_sorted=False)  # (sum(lengths), vocab_size)\n",
        "        targets, _, _, _ = pack_padded_sequence(input=targets,lengths=lengths.to(\"cpu\"), batch_first=True, enforce_sorted=False)  # (sum(lengths))\n",
        "        target_vector = torch.zeros_like(inputs).scatter(dim=1, index=targets.unsqueeze(1), value=1.).to(device)  # (sum(lengths), n_classes), one-hot\n",
        "        target_vector = target_vector * (1. - self.eps) + self.eps / target_vector.size(1)  # (sum(lengths), n_classes), \"smoothed\" one-hot\n",
        "\n",
        "        # Compute smoothed cross-entropy loss\n",
        "        loss = (-1 * target_vector * F.log_softmax(inputs, dim=1)).sum(dim=1)  # (sum(lengths))\n",
        "        # Compute mean loss\n",
        "        loss = torch.mean(loss)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud2uQi0IskMZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "vocab_size = 234\n",
        "\n",
        "# Define the dimensionality of the character embedding\n",
        "embedding_dim = 32\n",
        "\n",
        "# Create a random character embedding matrix\n",
        "embedding_matrix = np.random.rand(vocab_size, embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQSrh6--ujsF"
      },
      "outputs": [],
      "source": [
        "#@title Vocab Map\n",
        "vocabMap = {\"<PAD>\": 0, \" \": 1, \"<BOS>\": 2, \"<EOS>\": 3, \"ህ\": 4,\"ል\": 5, \"ም\": 6, \"ር\": 7, \"ስ\": 8, \"ሽ\": 9, \"ቅ\": 10, \"ብ\": 11, \"ቭ\": 12, \"ት\": 13, \"ች\": 14, \"ን\": 15, \"ኝ\": 16, \"ክ\": 17, \"ው\": 18, \"ዝ\": 19, \"ዥ\": 20, \"ይ\": 21, \"ድ\": 22, \"ጅ\": 23, \"ግ\": 24, \"ጥ\": 25, \"ጭ\": 26, \"ጵ\": 27, \"ጽ\": 28, \"ፍ\": 29, \"ፕ\": 30, \"ኧ\": 31, \"አ\": 32, \"ኡ\": 33, \"ኢ\": 34, \"ኤ\": 35, \"እ\": 36, \"ኦ\": 37, \"ኸ\": 38, \"ሀ\": 39, \"ሁ\": 40, \"ሂ\": 41, \"ሄ\": 42, \"ሆ\": 43, \"ለ\": 44, \"ሉ\": 45, \"ሊ\": 46, \"ላ\": 47, \"ሌ\": 48, \"ሎ\": 49, \"መ\": 50, \"ሙ\": 51, \"ሚ\": 52, \"ማ\": 53, \"ሜ\": 54, \"ሞ\": 55, \"ረ\": 56, \"ሩ\": 57, \"ሪ\": 58, \"ራ\": 59, \"ሬ\": 60, \"ሮ\": 61, \"ሰ\": 62, \"ሱ\": 63, \"ሲ\": 64, \"ሳ\": 65, \"ሴ\": 66, \"ሶ\": 67, \"ሸ\": 68, \"ሹ\": 69, \"ሺ\": 70, \"ሻ\": 71, \"ሼ\": 72, \"ሾ\": 73, \"ቀ\": 74, \"ቁ\": 75, \"ቂ\": 76, \"ቃ\": 77, \"ቄ\": 78, \"ቆ\": 79, \"በ\": 80, \"ቡ\": 81, \"ቢ\": 82, \"ባ\": 83, \"ቤ\": 84, \"ቦ\": 85, \"ቨ\": 86, \"ቩ\": 87, \"ቪ\": 88, \"ቫ\": 89, \"ቬ\": 90, \"ቮ\": 91, \"ተ\": 92, \"ቱ\": 93, \"ቲ\": 94, \"ታ\": 95, \"ቴ\": 96, \"ቶ\": 97, \"ቸ\": 98, \"ቹ\": 99, \"ቺ\": 100, \"ቻ\": 101, \"ቼ\": 102, \"ቾ\": 103, \"ነ\": 104, \"ኑ\": 105, \"ኒ\": 106, \"ና\": 107, \"ኔ\": 108, \"ኖ\": 109, \"ኘ\": 110, \"ኙ\": 111, \"ኚ\": 112, \"ኛ\": 113, \"ኜ\": 114, \"ኞ\": 115, \"ከ\": 116, \"ኩ\": 117, \"ኪ\": 118, \"ካ\": 119, \"ኬ\": 120, \"ኮ\": 121, \"ወ\": 122, \"ዉ\": 123, \"ዊ\": 124, \"ዋ\": 125, \"ዌ\": 126, \"ዎ\": 127, \"ዘ\": 128, \"ዙ\": 129, \"ዚ\": 130, \"ዛ\": 131, \"ዜ\": 132, \"ዞ\": 133, \"ዠ\": 134, \"ዡ\": 135, \"ዢ\": 136, \"ዣ\": 137, \"ዤ\": 138, \"ዦ\": 139, \"የ\": 140, \"ዩ\": 141, \"ዪ\": 142, \"ያ\": 143, \"ዬ\": 144, \"ዮ\": 145, \"ደ\": 146, \"ዱ\": 147, \"ዲ\": 148, \"ዳ\": 149, \"ዴ\": 150, \"ዶ\": 151, \"ጀ\": 152, \"ጁ\": 153, \"ጂ\": 154, \"ጃ\": 155, \"ጄ\": 156, \"ጆ\": 157, \"ገ\": 158, \"ጉ\": 159, \"ጊ\": 160, \"ጋ\": 161, \"ጌ\": 162, \"ጐ\": 163, \"ጠ\": 164, \"ጡ\": 165, \"ጢ\": 166, \"ጣ\": 167, \"ጤ\": 168, \"ጦ\": 169, \"ጨ\": 170, \"ጩ\": 171, \"ጪ\": 172, \"ጫ\": 173, \"ጬ\": 174, \"ጮ\": 175, \"ጰ\": 176, \"ጱ\": 177, \"ጲ\": 178, \"ጳ\": 179, \"ጴ\": 180, \"ጶ\": 181, \"ጸ\": 182, \"ጹ\": 183, \"ጺ\": 184, \"ጻ\": 185, \"ጼ\": 186, \"ጾ\": 187, \"ፈ\": 188, \"ፉ\": 189, \"ፊ\": 190, \"ፋ\": 191, \"ፌ\": 192, \"ፎ\": 193, \"ፐ\": 194, \"ፑ\": 195, \"ፒ\": 196, \"ፓ\": 197, \"ፔ\": 198, \"ፖ\": 199, \"ኋ\": 200, \"ሏ\": 201, \"ሟ\": 202, \"ሯ\": 203, \"ሷ\": 204, \"ሿ\": 205, \"ቋ\": 206, \"ቧ\": 207, \"ቯ\": 208, \"ቷ\": 209, \"ቿ\": 210, \"ኗ\": 211, \"ኟ\": 212, \"ኳ\": 213, \"ዟ\": 214, \"ዧ\": 215, \"ዷ\": 216, \"ጇ\": 217, \"ጓ\": 218, \"ጧ\": 219, \"ጯ\": 220, \"ጷ\": 221, \"ጿ\": 222, \"ፏ\": 223, \"ፗ\": 224, \"ጔ\": 225, \"ኴ\": 226, \"ኌ\": 227, \"ቌ\": 228, \"ጒ\": 229, \"ኲ\": 230, \"ኊ\": 231, \"ቊ\": 232, \"\\n\": 233}\n",
        "\n",
        "# Ignore ids=[0, 2, 3]\n",
        "idToChar = {1:\" \", 4: 'ህ', 5: 'ል', 6: 'ም', 7: 'ር', 8: 'ስ', 9: 'ሽ', 10: 'ቅ', 11: 'ብ', 12: 'ቭ', 13: 'ት', 14: 'ች', 15: 'ን', 16: 'ኝ', 17: 'ክ', 18: 'ው', 19: 'ዝ', 20: 'ዥ', 21: 'ይ', 22: 'ድ', 23: 'ጅ', 24: 'ግ', 25: 'ጥ', 26: 'ጭ', 27: 'ጵ', 28: 'ጽ', 29: 'ፍ', 30: 'ፕ', 31: 'ኧ', 32: 'አ', 33: 'ኡ', 34: 'ኢ', 35: 'ኤ', 36: 'እ', 37: 'ኦ', 38: 'ኸ', 39: 'ሀ', 40: 'ሁ', 41: 'ሂ', 42: 'ሄ', 43: 'ሆ', 44: 'ለ', 45: 'ሉ', 46: 'ሊ', 47: 'ላ', 48: 'ሌ', 49: 'ሎ', 50: 'መ', 51: 'ሙ', 52: 'ሚ', 53: 'ማ', 54: 'ሜ', 55: 'ሞ', 56: 'ረ', 57: 'ሩ', 58: 'ሪ', 59: 'ራ', 60: 'ሬ', 61: 'ሮ', 62: 'ሰ', 63: 'ሱ', 64: 'ሲ', 65: 'ሳ', 66: 'ሴ', 67: 'ሶ', 68: 'ሸ', 69: 'ሹ', 70: 'ሺ', 71: 'ሻ', 72: 'ሼ', 73: 'ሾ', 74: 'ቀ', 75: 'ቁ', 76: 'ቂ', 77: 'ቃ', 78: 'ቄ', 79: 'ቆ', 80: 'በ', 81: 'ቡ', 82: 'ቢ', 83: 'ባ', 84: 'ቤ', 85: 'ቦ', 86: 'ቨ', 87: 'ቩ', 88: 'ቪ', 89: 'ቫ', 90: 'ቬ', 91: 'ቮ', 92: 'ተ', 93: 'ቱ', 94: 'ቲ', 95: 'ታ', 96: 'ቴ', 97: 'ቶ', 98: 'ቸ', 99: 'ቹ', 100: 'ቺ', 101: 'ቻ', 102: 'ቼ', 103: 'ቾ', 104: 'ነ', 105: 'ኑ', 106: 'ኒ', 107: 'ና', 108: 'ኔ', 109: 'ኖ', 110: 'ኘ', 111: 'ኙ', 112: 'ኚ', 113: 'ኛ', 114: 'ኜ', 115: 'ኞ', 116: 'ከ', 117: 'ኩ', 118: 'ኪ', 119: 'ካ', 120: 'ኬ', 121: 'ኮ', 122: 'ወ', 123: 'ዉ', 124: 'ዊ', 125: 'ዋ', 126: 'ዌ', 127: 'ዎ', 128: 'ዘ', 129: 'ዙ', 130: 'ዚ', 131: 'ዛ', 132: 'ዜ', 133: 'ዞ', 134: 'ዠ', 135: 'ዡ', 136: 'ዢ', 137: 'ዣ', 138: 'ዤ', 139: 'ዦ', 140: 'የ', 141: 'ዩ', 142: 'ዪ', 143: 'ያ', 144: 'ዬ', 145: 'ዮ', 146: 'ደ', 147: 'ዱ', 148: 'ዲ', 149: 'ዳ', 150: 'ዴ', 151: 'ዶ', 152: 'ጀ', 153: 'ጁ', 154: 'ጂ', 155: 'ጃ', 156: 'ጄ', 157: 'ጆ', 158: 'ገ', 159: 'ጉ', 160: 'ጊ', 161: 'ጋ', 162: 'ጌ', 163: 'ጐ', 164: 'ጠ', 165: 'ጡ', 166: 'ጢ', 167: 'ጣ', 168: 'ጤ', 169: 'ጦ', 170: 'ጨ', 171: 'ጩ', 172: 'ጪ', 173: 'ጫ', 174: 'ጬ', 175: 'ጮ', 176: 'ጰ', 177: 'ጱ', 178: 'ጲ', 179: 'ጳ', 180: 'ጴ', 181: 'ጶ', 182: 'ጸ', 183: 'ጹ', 184: 'ጺ', 185: 'ጻ', 186: 'ጼ', 187: 'ጾ', 188: 'ፈ', 189: 'ፉ', 190: 'ፊ', 191: 'ፋ', 192: 'ፌ', 193: 'ፎ', 194: 'ፐ', 195: 'ፑ', 196: 'ፒ', 197: 'ፓ', 198: 'ፔ', 199: 'ፖ', 200: 'ኋ', 201: 'ሏ', 202: 'ሟ', 203: 'ሯ', 204: 'ሷ', 205: 'ሿ', 206: 'ቋ', 207: 'ቧ', 208: 'ቯ', 209: 'ቷ', 210: 'ቿ', 211: 'ኗ', 212: 'ኟ', 213: 'ኳ', 214: 'ዟ', 215: 'ዧ', 216: 'ዷ', 217: 'ጇ', 218: 'ጓ', 219: 'ጧ', 220: 'ጯ', 221: 'ጷ', 222: 'ጿ', 223: 'ፏ', 224: 'ፗ', 225: 'ጔ', 226: 'ኴ', 227: 'ኌ', 228: 'ቌ', 229: 'ጒ', 230: 'ኲ', 231: 'ኊ', 232: 'ቊ', 233: \"\\n\"}\n",
        "\n",
        "def encodeString(sentence: str):\n",
        "  splitted = [char for char in sentence]\n",
        "  if len(splitted)==0:\n",
        "    raise Exception(\"Empty sentence\")\n",
        "  return [ vocabMap.get(item, 1) for item in splitted]\n",
        "\n",
        "def encodeSentences(sentences, bos: bool, eos: bool):\n",
        "  return [ addEOSBOS(encodeString(sentence), bos, eos) for sentence in sentences ]\n",
        "\n",
        "def addEOSBOS(splitted: list, bos:bool, eos:bool):\n",
        "  if bos:\n",
        "    splitted.insert(0, 2)\n",
        "  if eos:\n",
        "    splitted.append(3)\n",
        "  return splitted\n",
        "\n",
        "def decodeString(prediction:list):\n",
        "  return \"\".join(\n",
        "      [\n",
        "          idToChar.get(charI, \"\") for charI in prediction\n",
        "          ]\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqt2ZKtAJ-px"
      },
      "outputs": [],
      "source": [
        "#@title Positional Encoder\n",
        "def get_positional_encoding(d_model, max_length=100):\n",
        "    \"\"\"\n",
        "    Computes positional encoding as defined in the paper.\n",
        "\n",
        "    :param d_model: size of vectors throughout the transformer model\n",
        "    :param max_length: maximum sequence length up to which positional encodings must be calculated\n",
        "    :return: positional encoding, a tensor of size (1, max_length, d_model)\n",
        "    \"\"\"\n",
        "    positional_encoding = torch.zeros((max_length, d_model))  # (max_length, d_model)\n",
        "    for i in range(max_length):\n",
        "        for j in range(d_model):\n",
        "            if j % 2 == 0:\n",
        "                positional_encoding[i, j] = math.sin(i / math.pow(10000, j / d_model))\n",
        "            else:\n",
        "                positional_encoding[i, j] = math.cos(i / math.pow(10000, (j - 1) / d_model))\n",
        "\n",
        "    positional_encoding = positional_encoding.unsqueeze(0)  # (1, max_length, d_model)\n",
        "\n",
        "    return positional_encoding\n",
        "\n",
        "\n",
        "def get_lr(step, d_model, warmup_steps):\n",
        "    lr = 2. * math.pow(d_model, -0.5) * min(math.pow(step, -0.5), step * math.pow(warmup_steps, -1.5))\n",
        "    return lr\n",
        "\n",
        "\n",
        "def save_checkpoint(epoch, model, optimizer, prefix=''):\n",
        "    state = {'epoch': epoch,\n",
        "             'model': model,\n",
        "             'optimizer': optimizer}\n",
        "    filename = \"/content/drive/MyDrive/MTModel/seq2seq_last_verr_0.902_new.pth.tar\" #\"/content/drive/MyDrive/MTModel/seq2seq2_finetuned_1.pth.tar\" #\"/content/drive/MyDrive/MTModel/seq2seq_last.pth.tar\"\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def change_lr(optimizer, new_lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = new_lr\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJjGRP83xAhp"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/train.join .\n",
        "!cp /content/drive/MyDrive/train.spa .\n",
        "!cp /content/drive/MyDrive/val.join . && cp /content/drive/MyDrive/val.spa .\n",
        "# !cp train.join /content/drive/MyDrive/ && cp train.spa /content/drive/MyDrive/\n",
        "# !cp val.join /content/drive/MyDrive/ && cp val.spa /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8QHO3lcCmuF"
      },
      "outputs": [],
      "source": [
        "# !cp /content/drive/MyDrive/train.txt\n",
        "# !cp train.join /content/drive/MyDrive/train.join && cp train.spa /content/drive/MyDrive/train.spa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wflk-dTOLg7G"
      },
      "source": [
        "Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF6t7-SRLiYQ"
      },
      "outputs": [],
      "source": [
        "#@title Sequence Loader\n",
        "class SequenceLoader(object):\n",
        "    def __init__(self, data_folder, source_suffix, target_suffix, split, tokens_in_batch):\n",
        "        self.tokens_in_batch = tokens_in_batch\n",
        "        self.source_suffix = source_suffix\n",
        "        self.target_suffix = target_suffix\n",
        "        assert split.lower() in {\"train\", \"val\",\n",
        "                                 \"test\"}, \"'split' must be one of 'train', 'val', 'test'! (case-insensitive)\"\n",
        "        self.split = split.lower()\n",
        "\n",
        "        # Is this for training?\n",
        "        self.for_training = self.split == \"train\"\n",
        "        # Load data]\n",
        "        print(\"Path: \", data_folder+ split+\".\"+source_suffix)\n",
        "        with open(data_folder+ split+\".\"+source_suffix, \"r\", encoding =\"utf-8\") as f:\n",
        "            # print(f.read())\n",
        "            source_data = f.read().split(\"\\n\")[:-1]\n",
        "        with open(data_folder+ split +\".\"+target_suffix, \"r\", encoding =\"utf-8\") as f:\n",
        "            target_data = f.read().split(\"\\n\")[:-1]\n",
        "        print(\"Source data:\", len(source_data), \" Target Data: \", len(target_data))\n",
        "        assert len(source_data) == len(target_data), \"There are a different number of source or target sequences!\"\n",
        "\n",
        "        source_lengths = [len(s) for s in encodeSentences(source_data, bos=False, eos=False)]\n",
        "        target_lengths = [len(t) for t in encodeSentences(target_data, bos=True,\n",
        "                                                                eos=True)]  # target language sequences have <BOS> and <EOS> tokens\n",
        "        self.data = list(zip(source_data, target_data, source_lengths, target_lengths))\n",
        "\n",
        "        # If for training, pre-sort by target lengths - required for itertools.groupby() later\n",
        "        if self.for_training:\n",
        "            self.data.sort(key=lambda x: x[3])\n",
        "\n",
        "        # Create batches\n",
        "        self.create_batches()\n",
        "\n",
        "    def create_batches(self):\n",
        "        \"\"\"\n",
        "        Prepares batches for one epoch.\n",
        "        \"\"\"\n",
        "\n",
        "        # If training\n",
        "        if self.for_training:\n",
        "            # Group or chunk based on target sequence lengths\n",
        "            chunks = [list(g) for _, g in groupby(self.data, key=lambda x: x[3])]\n",
        "\n",
        "            # Create batches, each with the same target sequence length\n",
        "            self.all_batches = list()\n",
        "            for chunk in chunks:\n",
        "                # Sort inside chunk by source sequence lengths, so that a batch would also have similar source sequence lengths\n",
        "                chunk.sort(key=lambda x: x[2])\n",
        "                # How many sequences in each batch? Divide expected batch size (i.e. tokens) by target sequence length in this chunk\n",
        "                seqs_per_batch = self.tokens_in_batch // chunk[0][3]\n",
        "                # Split chunk into batches\n",
        "                self.all_batches.extend([chunk[i: i + seqs_per_batch] for i in range(0, len(chunk), seqs_per_batch)])\n",
        "\n",
        "            # Shuffle batches\n",
        "            shuffle(self.all_batches)\n",
        "            self.n_batches = len(self.all_batches)\n",
        "            self.current_batch = -1\n",
        "        else:\n",
        "            # Simply return once pair at a time\n",
        "            self.all_batches = [[d] for d in self.data]\n",
        "            self.n_batches = len(self.all_batches)\n",
        "            self.current_batch = -1\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "        Iterators require this method defined.\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # Update current batch index\n",
        "        self.current_batch += 1\n",
        "        try:\n",
        "            source_data, target_data, source_lengths, target_lengths = zip(*self.all_batches[self.current_batch])\n",
        "        # Stop iteration once all batches are iterated through\n",
        "        except IndexError:\n",
        "            raise StopIteration\n",
        "\n",
        "\n",
        "\n",
        "        # print(\"Source Data: \", source_data)\n",
        "        # print(\"Target Data: \", target_data)\n",
        "        # print(\"<Source data>: \", source_data)\n",
        "\n",
        "        source_data = encodeSentences(source_data, bos=False, eos=False)\n",
        "        # print(\"<\\Source data>: \", len(source_data))\n",
        "\n",
        "        # print(\"<Target data>: \", target_data)\n",
        "        target_data = encodeSentences(target_data, bos=True, eos=True)\n",
        "        # print(\"<\\Target data>: \", len(target_data))\n",
        "\n",
        "\n",
        "        # print(source_data)\n",
        "        # Convert source and target sequences as padded tensors\n",
        "        source_data = pad_sequence(sequences=[torch.LongTensor(s) for s in source_data],\n",
        "                                   batch_first=True,\n",
        "                                   padding_value=vocabMap['<PAD>'])\n",
        "        target_data = pad_sequence(sequences=[torch.LongTensor(t) for t in target_data],\n",
        "                                   batch_first=True,\n",
        "                                   padding_value=vocabMap['<PAD>'])\n",
        "\n",
        "        # print(\"Source Data: \", source_data)\n",
        "        # print(\"Target Data: \", target_data)\n",
        "        # print(\"<\\Source data>: After padding: \", len(source_data))\n",
        "        # print(\"<\\Target data>: After Padding: \", len(target_data))\n",
        "\n",
        "\n",
        "        # Convert lengths to tensors\n",
        "        source_lengths = torch.LongTensor(source_lengths)\n",
        "        target_lengths = torch.LongTensor(target_lengths)\n",
        "\n",
        "        return source_data, target_data, source_lengths, target_lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8jQaOOgKN3S"
      },
      "source": [
        "Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WMZ61OzJp5c"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSX-5siRt7xs",
        "outputId": "693446b5-c6c5-4829-a0eb-8cabd53b6e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Learning Rate:  5.5242717280199024e-06\n",
            "Device:  cuda\n",
            "Path:  ./train.join\n",
            "Source data: 24978  Target Data:  24978\n",
            "Path:  ./val.join\n",
            "Source data: 358  Target Data:  358\n",
            "Model initialized.\n",
            "Epoch 1/4-----Batch 80/1203-----Step 20/1000-----Data Time 0.004 (0.005)-----Step Time 15.292 (14.277)-----Loss 4.5889 (5.3500)\n",
            "Epoch 1/4-----Batch 160/1203-----Step 40/1000-----Data Time 0.007 (0.005)-----Step Time 16.750 (14.192)-----Loss 4.3384 (4.8893)\n",
            "Epoch 1/4-----Batch 240/1203-----Step 60/1000-----Data Time 0.004 (0.005)-----Step Time 14.979 (14.071)-----Loss 4.0651 (4.6646)\n",
            "Epoch 1/4-----Batch 320/1203-----Step 80/1000-----Data Time 0.001 (0.005)-----Step Time 9.250 (13.753)-----Loss 3.8784 (4.5195)\n",
            "Epoch 1/4-----Batch 400/1203-----Step 100/1000-----Data Time 0.004 (0.005)-----Step Time 8.767 (13.685)-----Loss 3.7630 (4.3937)\n",
            "Epoch 1/4-----Batch 480/1203-----Step 120/1000-----Data Time 0.002 (0.005)-----Step Time 9.718 (13.747)-----Loss 3.6135 (4.2882)\n",
            "Epoch 1/4-----Batch 560/1203-----Step 140/1000-----Data Time 0.004 (0.005)-----Step Time 11.121 (13.792)-----Loss 3.6371 (4.2048)\n",
            "Epoch 1/4-----Batch 640/1203-----Step 160/1000-----Data Time 0.004 (0.005)-----Step Time 15.439 (13.954)-----Loss 3.8070 (4.1353)\n",
            "Epoch 1/4-----Batch 720/1203-----Step 180/1000-----Data Time 0.004 (0.005)-----Step Time 12.568 (13.976)-----Loss 3.6356 (4.0797)\n",
            "Epoch 1/4-----Batch 800/1203-----Step 200/1000-----Data Time 0.001 (0.005)-----Step Time 11.726 (14.059)-----Loss 3.4129 (4.0326)\n",
            "Epoch 1/4-----Batch 880/1203-----Step 220/1000-----Data Time 0.004 (0.005)-----Step Time 17.750 (14.061)-----Loss 3.5646 (3.9941)\n",
            "Epoch 1/4-----Batch 960/1203-----Step 240/1000-----Data Time 0.003 (0.005)-----Step Time 12.328 (14.054)-----Loss 3.5465 (3.9592)\n",
            "Epoch 1/4-----Batch 1040/1203-----Step 260/1000-----Data Time 0.004 (0.005)-----Step Time 16.627 (14.042)-----Loss 3.5806 (3.9293)\n",
            "Epoch 1/4-----Batch 1120/1203-----Step 280/1000-----Data Time 0.011 (0.005)-----Step Time 13.994 (14.006)-----Loss 3.4904 (3.9018)\n",
            "Epoch 1/4-----Batch 1200/1203-----Step 300/1000-----Data Time 0.008 (0.005)-----Step Time 16.370 (14.001)-----Loss 3.5591 (3.8762)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 358/358 [00:10<00:00, 32.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 3.570\n",
            "\n",
            "\n",
            "Epoch 2/4-----Batch 80/1203-----Step 320/1000-----Data Time 0.007 (0.005)-----Step Time 15.209 (13.727)-----Loss 3.4939 (3.4702)\n",
            "Epoch 2/4-----Batch 160/1203-----Step 340/1000-----Data Time 0.003 (0.005)-----Step Time 10.841 (13.373)-----Loss 3.5044 (3.4631)\n",
            "Epoch 2/4-----Batch 240/1203-----Step 360/1000-----Data Time 0.004 (0.005)-----Step Time 12.780 (13.524)-----Loss 3.3263 (3.4397)\n",
            "Epoch 2/4-----Batch 320/1203-----Step 380/1000-----Data Time 0.007 (0.005)-----Step Time 11.413 (13.799)-----Loss 3.3770 (3.4157)\n",
            "Epoch 2/4-----Batch 400/1203-----Step 400/1000-----Data Time 0.002 (0.005)-----Step Time 12.325 (13.769)-----Loss 3.1852 (3.3903)\n",
            "Epoch 2/4-----Batch 480/1203-----Step 420/1000-----Data Time 0.004 (0.005)-----Step Time 12.340 (13.671)-----Loss 3.2552 (3.3685)\n",
            "Epoch 2/4-----Batch 560/1203-----Step 440/1000-----Data Time 0.004 (0.005)-----Step Time 14.922 (13.719)-----Loss 3.1457 (3.3431)\n",
            "Epoch 2/4-----Batch 640/1203-----Step 460/1000-----Data Time 0.008 (0.005)-----Step Time 13.885 (13.666)-----Loss 3.2116 (3.3194)\n",
            "Epoch 2/4-----Batch 720/1203-----Step 480/1000-----Data Time 0.004 (0.005)-----Step Time 16.966 (13.737)-----Loss 3.0004 (3.2943)\n",
            "Epoch 2/4-----Batch 800/1203-----Step 500/1000-----Data Time 0.004 (0.005)-----Step Time 16.177 (13.775)-----Loss 3.0949 (3.2735)\n",
            "Epoch 2/4-----Batch 880/1203-----Step 520/1000-----Data Time 0.004 (0.005)-----Step Time 15.657 (13.814)-----Loss 3.1005 (3.2547)\n",
            "Epoch 2/4-----Batch 960/1203-----Step 540/1000-----Data Time 0.005 (0.005)-----Step Time 15.174 (13.892)-----Loss 2.8647 (3.2316)\n",
            "Epoch 2/4-----Batch 1040/1203-----Step 560/1000-----Data Time 0.004 (0.005)-----Step Time 15.191 (13.929)-----Loss 2.9265 (3.2101)\n",
            "Epoch 2/4-----Batch 1120/1203-----Step 580/1000-----Data Time 0.008 (0.005)-----Step Time 8.569 (13.892)-----Loss 2.9902 (3.1931)\n",
            "Epoch 2/4-----Batch 1200/1203-----Step 600/1000-----Data Time 0.005 (0.005)-----Step Time 13.092 (13.849)-----Loss 2.8982 (3.1789)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 358/358 [00:11<00:00, 31.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 2.979\n",
            "\n",
            "\n",
            "Epoch 3/4-----Batch 76/1203-----Step 620/1000-----Data Time 0.002 (0.005)-----Step Time 11.182 (14.072)-----Loss 2.9864 (2.9101)\n",
            "Epoch 3/4-----Batch 156/1203-----Step 640/1000-----Data Time 0.002 (0.005)-----Step Time 14.147 (14.341)-----Loss 2.7654 (2.8935)\n",
            "Epoch 3/4-----Batch 236/1203-----Step 660/1000-----Data Time 0.007 (0.005)-----Step Time 15.724 (14.021)-----Loss 2.7798 (2.8744)\n",
            "Epoch 3/4-----Batch 316/1203-----Step 680/1000-----Data Time 0.005 (0.005)-----Step Time 14.142 (13.826)-----Loss 2.7872 (2.8574)\n",
            "Epoch 3/4-----Batch 396/1203-----Step 700/1000-----Data Time 0.004 (0.005)-----Step Time 14.788 (13.896)-----Loss 2.8241 (2.8409)\n",
            "Epoch 3/4-----Batch 476/1203-----Step 720/1000-----Data Time 0.005 (0.005)-----Step Time 15.175 (13.962)-----Loss 2.7052 (2.8261)\n",
            "Epoch 3/4-----Batch 556/1203-----Step 740/1000-----Data Time 0.005 (0.005)-----Step Time 14.969 (13.990)-----Loss 2.6965 (2.8098)\n",
            "Epoch 3/4-----Batch 636/1203-----Step 760/1000-----Data Time 0.004 (0.005)-----Step Time 14.305 (13.999)-----Loss 2.6367 (2.7943)\n",
            "Epoch 3/4-----Batch 716/1203-----Step 780/1000-----Data Time 0.008 (0.005)-----Step Time 15.925 (14.024)-----Loss 2.6305 (2.7752)\n",
            "Epoch 3/4-----Batch 796/1203-----Step 800/1000-----Data Time 0.003 (0.005)-----Step Time 14.201 (13.887)-----Loss 2.5222 (2.7617)\n",
            "Epoch 3/4-----Batch 876/1203-----Step 820/1000-----Data Time 0.008 (0.005)-----Step Time 16.274 (13.872)-----Loss 2.6273 (2.7437)\n",
            "Epoch 3/4-----Batch 956/1203-----Step 840/1000-----Data Time 0.012 (0.005)-----Step Time 13.196 (13.887)-----Loss 2.4810 (2.7246)\n",
            "Epoch 3/4-----Batch 1036/1203-----Step 860/1000-----Data Time 0.004 (0.005)-----Step Time 14.754 (13.914)-----Loss 2.4777 (2.7026)\n",
            "Epoch 3/4-----Batch 1116/1203-----Step 880/1000-----Data Time 0.010 (0.005)-----Step Time 7.988 (13.905)-----Loss 2.4529 (2.6815)\n",
            "Epoch 3/4-----Batch 1196/1203-----Step 900/1000-----Data Time 0.007 (0.005)-----Step Time 15.515 (13.901)-----Loss 2.5789 (2.6562)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 358/358 [00:11<00:00, 32.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 1.957\n",
            "\n",
            "\n",
            "Epoch 4/4-----Batch 72/1203-----Step 920/1000-----Data Time 0.006 (0.005)-----Step Time 14.768 (13.663)-----Loss 2.3719 (2.2987)\n",
            "Epoch 4/4-----Batch 152/1203-----Step 940/1000-----Data Time 0.003 (0.005)-----Step Time 7.938 (13.414)-----Loss 2.4402 (2.2751)\n",
            "Epoch 4/4-----Batch 232/1203-----Step 960/1000-----Data Time 0.007 (0.005)-----Step Time 14.292 (13.729)-----Loss 2.1795 (2.2421)\n",
            "Epoch 4/4-----Batch 312/1203-----Step 980/1000-----Data Time 0.004 (0.005)-----Step Time 15.417 (13.776)-----Loss 2.3009 (2.2146)\n",
            "Epoch 4/4-----Batch 392/1203-----Step 1000/1000-----Data Time 0.005 (0.005)-----Step Time 14.163 (13.612)-----Loss 2.0301 (2.1903)\n",
            "Epoch 4/4-----Batch 472/1203-----Step 1020/1000-----Data Time 0.005 (0.005)-----Step Time 13.568 (13.639)-----Loss 2.0572 (2.1707)\n",
            "Epoch 4/4-----Batch 552/1203-----Step 1040/1000-----Data Time 0.002 (0.005)-----Step Time 9.843 (13.631)-----Loss 1.8832 (2.1443)\n",
            "Epoch 4/4-----Batch 632/1203-----Step 1060/1000-----Data Time 0.006 (0.005)-----Step Time 13.401 (13.769)-----Loss 2.1345 (2.1215)\n",
            "Epoch 4/4-----Batch 712/1203-----Step 1080/1000-----Data Time 0.005 (0.005)-----Step Time 15.050 (13.780)-----Loss 1.9662 (2.1091)\n",
            "Epoch 4/4-----Batch 792/1203-----Step 1100/1000-----Data Time 0.004 (0.005)-----Step Time 12.275 (13.793)-----Loss 1.9615 (2.0896)\n",
            "Epoch 4/4-----Batch 872/1203-----Step 1120/1000-----Data Time 0.004 (0.005)-----Step Time 13.377 (13.753)-----Loss 1.8148 (2.0734)\n",
            "Epoch 4/4-----Batch 952/1203-----Step 1140/1000-----Data Time 0.004 (0.005)-----Step Time 14.491 (13.730)-----Loss 1.9686 (2.0592)\n",
            "Epoch 4/4-----Batch 1032/1203-----Step 1160/1000-----Data Time 0.004 (0.005)-----Step Time 16.127 (13.813)-----Loss 1.7305 (2.0490)\n",
            "Epoch 4/4-----Batch 1112/1203-----Step 1180/1000-----Data Time 0.004 (0.005)-----Step Time 14.001 (13.876)-----Loss 1.9498 (2.0338)\n",
            "Epoch 4/4-----Batch 1192/1203-----Step 1200/1000-----Data Time 0.007 (0.005)-----Step Time 14.958 (13.826)-----Loss 1.9687 (2.0183)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 358/358 [00:11<00:00, 31.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 1.600\n",
            "\n",
            "\n",
            "Epoch 5/4-----Batch 68/1203-----Step 1220/1000-----Data Time 0.005 (0.005)-----Step Time 14.605 (14.160)-----Loss 1.7561 (1.7572)\n",
            "Epoch 5/4-----Batch 148/1203-----Step 1240/1000-----Data Time 0.007 (0.005)-----Step Time 15.883 (14.474)-----Loss 1.8688 (1.7571)\n",
            "Epoch 5/4-----Batch 228/1203-----Step 1260/1000-----Data Time 0.007 (0.005)-----Step Time 15.362 (13.989)-----Loss 1.9511 (1.7625)\n",
            "Epoch 5/4-----Batch 308/1203-----Step 1280/1000-----Data Time 0.003 (0.005)-----Step Time 13.392 (14.033)-----Loss 1.6268 (1.7574)\n",
            "Epoch 5/4-----Batch 388/1203-----Step 1300/1000-----Data Time 0.002 (0.005)-----Step Time 11.182 (14.186)-----Loss 1.4042 (1.7419)\n",
            "Epoch 5/4-----Batch 468/1203-----Step 1320/1000-----Data Time 0.004 (0.005)-----Step Time 16.192 (13.967)-----Loss 1.7107 (1.7336)\n",
            "Epoch 5/4-----Batch 548/1203-----Step 1340/1000-----Data Time 0.008 (0.005)-----Step Time 12.102 (13.856)-----Loss 1.5548 (1.7266)\n",
            "Epoch 5/4-----Batch 628/1203-----Step 1360/1000-----Data Time 0.005 (0.005)-----Step Time 12.518 (13.879)-----Loss 1.9540 (1.7163)\n",
            "Epoch 5/4-----Batch 708/1203-----Step 1380/1000-----Data Time 0.005 (0.005)-----Step Time 11.920 (13.899)-----Loss 1.4951 (1.7069)\n",
            "Epoch 5/4-----Batch 788/1203-----Step 1400/1000-----Data Time 0.005 (0.005)-----Step Time 14.012 (13.851)-----Loss 1.5190 (1.6989)\n",
            "Epoch 5/4-----Batch 868/1203-----Step 1420/1000-----Data Time 0.002 (0.005)-----Step Time 12.015 (13.904)-----Loss 1.5434 (1.6946)\n",
            "Epoch 5/4-----Batch 948/1203-----Step 1440/1000-----Data Time 0.004 (0.005)-----Step Time 10.973 (13.889)-----Loss 1.6010 (1.6848)\n",
            "Epoch 5/4-----Batch 1028/1203-----Step 1460/1000-----Data Time 0.004 (0.005)-----Step Time 16.446 (13.931)-----Loss 1.8352 (1.6829)\n",
            "Epoch 5/4-----Batch 1108/1203-----Step 1480/1000-----Data Time 0.004 (0.005)-----Step Time 14.254 (13.953)-----Loss 1.5445 (1.6729)\n",
            "Epoch 5/4-----Batch 1188/1203-----Step 1500/1000-----Data Time 0.002 (0.005)-----Step Time 7.551 (13.935)-----Loss 1.5575 (1.6665)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 358/358 [00:10<00:00, 33.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 1.408\n",
            "\n",
            "\n",
            "Epoch 6/4-----Batch 68/1203-----Step 1520/1000-----Data Time 0.008 (0.005)-----Step Time 11.781 (13.361)-----Loss 1.4814 (1.5781)\n",
            "Epoch 6/4-----Batch 148/1203-----Step 1540/1000-----Data Time 0.008 (0.005)-----Step Time 16.102 (14.024)-----Loss 1.4474 (1.5592)\n",
            "Epoch 6/4-----Batch 228/1203-----Step 1560/1000-----Data Time 0.004 (0.005)-----Step Time 13.203 (13.993)-----Loss 1.4036 (1.5316)\n",
            "Epoch 6/4-----Batch 308/1203-----Step 1580/1000-----Data Time 0.004 (0.005)-----Step Time 11.231 (14.056)-----Loss 1.7081 (1.5055)\n",
            "Epoch 6/4-----Batch 388/1203-----Step 1600/1000-----Data Time 0.003 (0.005)-----Step Time 12.020 (13.908)-----Loss 1.3213 (1.5092)\n",
            "Epoch 6/4-----Batch 468/1203-----Step 1620/1000-----Data Time 0.002 (0.005)-----Step Time 9.014 (13.827)-----Loss 1.3481 (1.5153)\n",
            "Epoch 6/4-----Batch 548/1203-----Step 1640/1000-----Data Time 0.004 (0.005)-----Step Time 15.964 (13.877)-----Loss 1.6919 (1.5132)\n",
            "Epoch 6/4-----Batch 628/1203-----Step 1660/1000-----Data Time 0.004 (0.005)-----Step Time 13.123 (13.949)-----Loss 1.4164 (1.5079)\n",
            "Epoch 6/4-----Batch 708/1203-----Step 1680/1000-----Data Time 0.005 (0.005)-----Step Time 15.631 (13.944)-----Loss 1.3987 (1.4984)\n",
            "Epoch 6/4-----Batch 788/1203-----Step 1700/1000-----Data Time 0.005 (0.005)-----Step Time 10.807 (13.918)-----Loss 1.4789 (1.4961)\n",
            "Epoch 6/4-----Batch 868/1203-----Step 1720/1000-----Data Time 0.006 (0.005)-----Step Time 12.318 (13.891)-----Loss 1.6461 (1.4892)\n",
            "Epoch 6/4-----Batch 948/1203-----Step 1740/1000-----Data Time 0.004 (0.005)-----Step Time 10.438 (13.886)-----Loss 1.3445 (1.4826)\n",
            "Epoch 6/4-----Batch 1028/1203-----Step 1760/1000-----Data Time 0.004 (0.005)-----Step Time 12.766 (13.930)-----Loss 1.3914 (1.4780)\n",
            "Epoch 6/4-----Batch 1108/1203-----Step 1780/1000-----Data Time 0.005 (0.005)-----Step Time 11.698 (13.966)-----Loss 1.2808 (1.4742)\n",
            "Epoch 6/4-----Batch 1188/1203-----Step 1800/1000-----Data Time 0.004 (0.005)-----Step Time 15.620 (13.968)-----Loss 1.6026 (1.4704)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 358/358 [00:11<00:00, 30.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 1.349\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        " #@title Traininig\n",
        "# Data parameters\n",
        "data_folder = './'  # folder with data files\n",
        "\n",
        "# Model parameters\n",
        "d_model = 256\n",
        "n_heads = 12\n",
        "d_queries = 32\n",
        "d_values = 32\n",
        "d_inner = 2048\n",
        "n_layers = 8\n",
        "dropout = 0.1\n",
        "positional_encoding = get_positional_encoding(d_model=d_model, max_length=375)  # positional encodings up to the maximum possible pad-length\n",
        "\n",
        "checkpoint =  None #\"/content/drive/MyDrive/MTModel/seq2seq2.pth.tar\" # \"/content/drive/MyDrive/MTModel/seq2seq_last_verr_0.902_improved.pth.tar\"\n",
        "tokens_in_batch = 6000  # batch size in target language tokens\n",
        "batches_per_step = 25000 // tokens_in_batch  # perform a training step, i.e. update parameters, once every so many batches\n",
        "print_frequency = 20  # print status once every so many steps\n",
        "n_steps = 1000\n",
        "warmup_steps = 800\n",
        "step = 1\n",
        "lr = get_lr(step=step, d_model=d_model, warmup_steps=warmup_steps)\n",
        "print(\"\\nLearning Rate: \", lr)\n",
        "start_epoch = 0\n",
        "betas = (0.9, 0.98)\n",
        "epsilon = 1e-9\n",
        "label_smoothing = 0.1\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: \", device)\n",
        "cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Training and validation.\n",
        "    \"\"\"\n",
        "    global checkpoint, step, start_epoch, epoch, epochs\n",
        "\n",
        "    # Initialize data-loaders\n",
        "    train_loader = SequenceLoader(data_folder=\"./\",\n",
        "                                  source_suffix=\"join\",\n",
        "                                  target_suffix=\"spa\",\n",
        "                                  split=\"train\",\n",
        "                                  tokens_in_batch=tokens_in_batch)\n",
        "    val_loader = SequenceLoader(data_folder=\"./\",\n",
        "                                source_suffix=\"join\",\n",
        "                                target_suffix=\"spa\",\n",
        "                                split=\"val\",\n",
        "                                tokens_in_batch=tokens_in_batch)\n",
        "\n",
        "    # Initialize model or load checkpoint\n",
        "    if checkpoint is None:\n",
        "        model = Transformer(vocab_size=274,\n",
        "                            positional_encoding=positional_encoding,\n",
        "                            d_model=d_model,\n",
        "                            n_heads=n_heads,\n",
        "                            d_queries=d_queries,\n",
        "                            d_values=d_values,\n",
        "                            d_inner=d_inner,\n",
        "                            n_layers=n_layers,\n",
        "                            dropout=dropout)\n",
        "        optimizer = torch.optim.Adam(params=[p for p in model.parameters() if p.requires_grad],\n",
        "                                     lr=lr,\n",
        "                                     betas=betas,\n",
        "                                     eps=epsilon)\n",
        "\n",
        "    else:\n",
        "        checkpoint = torch.load(checkpoint)\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n",
        "        model = checkpoint['model']\n",
        "        optimizer = checkpoint['optimizer']\n",
        "\n",
        "    # Loss function\n",
        "    criterion = LabelSmoothedCE(eps=label_smoothing)\n",
        "\n",
        "    # Move to default device\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    # Find total epochs to train\n",
        "    epochs = (n_steps // (train_loader.n_batches // batches_per_step)) + 1\n",
        "\n",
        "    # Epochs\n",
        "    for epoch in range(start_epoch, epochs+100):\n",
        "        # Step\n",
        "        step = epoch * train_loader.n_batches // batches_per_step\n",
        "\n",
        "        optimizer.lr = lr\n",
        "        # One epoch's training\n",
        "        train_loader.create_batches()\n",
        "        train(train_loader=train_loader,\n",
        "              model=model,\n",
        "              criterion=criterion,\n",
        "              optimizer=optimizer,\n",
        "              epoch=epoch,\n",
        "              step=step)\n",
        "\n",
        "        # One epoch's validation\n",
        "        val_loader.create_batches()\n",
        "        validate(val_loader=val_loader,\n",
        "                 model=model,\n",
        "                 criterion=criterion)\n",
        "\n",
        "        # Save checkpoint\n",
        "        save_checkpoint(epoch, model, optimizer)\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch, step):\n",
        "    \"\"\"\n",
        "    One epoch's training.\n",
        "\n",
        "    :param train_loader: loader for training data\n",
        "    :param model: model\n",
        "    :param criterion: label-smoothed cross-entropy loss\n",
        "    :param optimizer: optimizer\n",
        "    :param epoch: epoch number\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    # Track some metrics\n",
        "    data_time = AverageMeter()  # data loading time\n",
        "    step_time = AverageMeter()  # forward prop. + back prop. time\n",
        "    losses = AverageMeter()  # loss\n",
        "\n",
        "    # Starting time\n",
        "    start_data_time = time.time()\n",
        "    start_step_time = time.time()\n",
        "\n",
        "    # Batches\n",
        "    for i, (source_sequences, target_sequences, source_sequence_lengths, target_sequence_lengths) in enumerate(\n",
        "            train_loader):\n",
        "\n",
        "        # Move to default device\n",
        "        source_sequences = source_sequences.to(device)  # (N, max_source_sequence_pad_length_this_batch)\n",
        "        target_sequences = target_sequences.to(device)  # (N, max_target_sequence_pad_length_this_batch)\n",
        "        source_sequence_lengths = source_sequence_lengths.to(device)  # (N)\n",
        "        target_sequence_lengths = target_sequence_lengths.to(device)  # (N)\n",
        "\n",
        "        # Time taken to load data\n",
        "        data_time.update(time.time() - start_data_time)\n",
        "\n",
        "        try:\n",
        "          # Forward prop.\n",
        "          predicted_sequences = model(source_sequences, target_sequences, source_sequence_lengths,\n",
        "                                      target_sequence_lengths)  # (N, max_target_sequence_pad_length_this_batch, vocab_size)\n",
        "        except:\n",
        "          predicted_sequences = source_sequences\n",
        "          raise Exception(\"Source Sequence: \", list(source_sequences))\n",
        "\n",
        "        # Note: If the target sequence is \"<BOS> w1 w2 ... wN <EOS> <PAD> <PAD> <PAD> <PAD> ...\"\n",
        "        # we should consider only \"w1 w2 ... wN <EOS>\" as <BOS> is not predicted\n",
        "        # Therefore, pads start after (length - 1) positions\n",
        "        loss = criterion(inputs=predicted_sequences,\n",
        "                         targets=target_sequences[:, 1:],\n",
        "                         lengths=target_sequence_lengths - 1)  # scalar\n",
        "\n",
        "        if loss == torch.nan:\n",
        "          print(\"Source Sequence: \", list(source_sequences))\n",
        "          print(\"Target Sequence: \", list(target_sequences))\n",
        "          raise Exception(\"Source Sequence: \", list(source_sequences))\n",
        "        # Backward prop.\n",
        "        (loss / batches_per_step).backward()\n",
        "\n",
        "        # Keep track of losses\n",
        "        losses.update(loss.item(), (target_sequence_lengths - 1).sum().item())\n",
        "\n",
        "        # Update model (i.e. perform a training step) only after gradients are accumulated from batches_per_step batches\n",
        "        if (i + 1) % batches_per_step == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This step is now complete\n",
        "            step += 1\n",
        "\n",
        "            # Update learning rate after each step\n",
        "            change_lr(optimizer, new_lr=get_lr(step=step, d_model=d_model, warmup_steps=warmup_steps))\n",
        "\n",
        "            # Time taken for this training step\n",
        "            step_time.update(time.time() - start_step_time)\n",
        "\n",
        "            # Print status\n",
        "            if step % print_frequency == 0:\n",
        "                print('Epoch {0}/{1}-----'\n",
        "                      'Batch {2}/{3}-----'\n",
        "                      'Step {4}/{5}-----'\n",
        "                      'Data Time {data_time.val:.3f} ({data_time.avg:.3f})-----'\n",
        "                      'Step Time {step_time.val:.3f} ({step_time.avg:.3f})-----'\n",
        "                      'Loss {losses.val:.4f} ({losses.avg:.4f})'.format(epoch + 1, epochs,\n",
        "                                                                        i + 1, train_loader.n_batches,\n",
        "                                                                        step, n_steps,\n",
        "                                                                        step_time=step_time,\n",
        "                                                                        data_time=data_time,\n",
        "                                                                        losses=losses))\n",
        "\n",
        "            # Reset step time\n",
        "            start_step_time = time.time()\n",
        "\n",
        "            # If this is the last one or two epochs, save checkpoints at regular intervals for averaging\n",
        "            if epoch in [epochs - 1, epochs - 2] and step % 1500 == 0:  # 'epoch' is 0-indexed\n",
        "                save_checkpoint(epoch, model, optimizer, prefix='step' + str(step) + \"_\")\n",
        "\n",
        "        # Reset data time\n",
        "        start_data_time = time.time()\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    \"\"\"\n",
        "    One epoch's validation.\n",
        "\n",
        "    :param val_loader: loader for validation data\n",
        "    :param model: model\n",
        "    :param criterion: label-smoothed cross-entropy loss\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        losses = AverageMeter()\n",
        "        # Batches\n",
        "        for i, (source_sequence, target_sequence, source_sequence_length, target_sequence_length) in enumerate(\n",
        "                tqdm(val_loader, total=val_loader.n_batches)):\n",
        "            source_sequence = source_sequence.to(device)  # (1, source_sequence_length)\n",
        "            target_sequence = target_sequence.to(device)  # (1, target_sequence_length)\n",
        "            source_sequence_length = source_sequence_length.to(device)  # (1)\n",
        "            target_sequence_length = target_sequence_length.to(device)  # (1)\n",
        "\n",
        "            # Forward prop.\n",
        "            predicted_sequence = model(source_sequence, target_sequence, source_sequence_length,\n",
        "                                       target_sequence_length)  # (1, target_sequence_length, vocab_size)\n",
        "\n",
        "            # Note: If the target sequence is \"<BOS> w1 w2 ... wN <EOS> <PAD> <PAD> <PAD> <PAD> ...\"\n",
        "            # we should consider only \"w1 w2 ... wN <EOS>\" as <BOS> is not predicted\n",
        "            # Therefore, pads start after (length - 1) position\n",
        "            loss = criterion(inputs=predicted_sequence, targets=target_sequence[:, 1:], lengths=target_sequence_length - 1)\n",
        "\n",
        "            # Keep track of losses\n",
        "            losses.update(loss.item(), (target_sequence_length - 1).sum().item())\n",
        "\n",
        "        print(\"\\nValidation loss: %.3f\\n\\n\" % losses.avg)\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "MCoXc1aXVTiR",
        "outputId": "27f069dc-7fb2-4791-b8fc-d02158922bec"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'get_positional_encoding' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-94d9eaadf30d>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpositional_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_positional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m233\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# positional encodings up to the maximum possible pad-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/MTModel/seq2seq_final.pth.tar\"\u001b[0m \u001b[0;31m#\"/content/drive/MyDrive/MTModel/seq2seq_last_verr_0.902.pth.tar\" # \"/content/drive/MyDrive/MTModel/seq2seq_last_verr_0.902_improved_wer_14.3.pth.tar\" # \"/content/drive/MyDrive/MTModel/seq2seq2_finetuned_1.pth.tar\" # \"/content/drive/MyDrive/MTModel/seq2seq2_finetuned.pth.tar\" #\"/content/drive/MyDrive/MTModel/seq2seq_final.pth.tar\" # \"/content/drive/MyDrive/MTModel/seq2seq_last_verr_0.902_improved.pth.tar\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_positional_encoding' is not defined"
          ]
        }
      ],
      "source": [
        " #@title Traininig\n",
        " \n",
        "# Data parameters\n",
        "data_folder = './'  # folder with data files\n",
        "\n",
        "# Model parameters\n",
        "d_model = 256\n",
        "n_heads = 12\n",
        "d_queries = 32\n",
        "d_values = 32\n",
        "d_inner = 2048\n",
        "n_layers = 8\n",
        "dropout = 0.1\n",
        "positional_encoding = get_positional_encoding(d_model=d_model, max_length=233)  # positional encodings up to the maximum possible pad-length\n",
        "\n",
        "checkpoint = \"/content/drive/MyDrive/MTModel/seq2seq_final.pth.tar\" #\"/content/drive/MyDrive/MTModel/seq2seq_last_verr_0.902.pth.tar\" # \"/content/drive/MyDrive/MTModel/seq2seq_last_verr_0.902_improved_wer_14.3.pth.tar\" # \"/content/drive/MyDrive/MTModel/seq2seq2_finetuned_1.pth.tar\" # \"/content/drive/MyDrive/MTModel/seq2seq2_finetuned.pth.tar\" #\"/content/drive/MyDrive/MTModel/seq2seq_final.pth.tar\" # \"/content/drive/MyDrive/MTModel/seq2seq_last_verr_0.902_improved.pth.tar\"\n",
        "tokens_in_batch = 8000  # batch size in target language tokens\n",
        "batches_per_step = 35000 // tokens_in_batch  # perform a training step, i.e. update parameters, once every so many batches\n",
        "print_frequency = 20  # print status once every so many steps\n",
        "n_steps = 20000\n",
        "warmup_steps = 800\n",
        "step = 1\n",
        "lr = get_lr(step=step, d_model=d_model, warmup_steps=warmup_steps)\n",
        "print(\"\\nLearning Rate: \", lr)\n",
        "start_epoch = 0\n",
        "betas = (0.9, 0.98)\n",
        "epsilon = 1e-9\n",
        "label_smoothing = 0.1\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: \", device)\n",
        "cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Training and validation.\n",
        "    \"\"\"\n",
        "    global checkpoint, step, start_epoch, epoch, epochs\n",
        "\n",
        "    # Initialize data-loaders\n",
        "    train_loader = SequenceLoader(data_folder=\"./\",\n",
        "                                  source_suffix=\"join\",\n",
        "                                  target_suffix=\"spa\",\n",
        "                                  split=\"train\",\n",
        "                                  tokens_in_batch=tokens_in_batch)\n",
        "    val_loader = SequenceLoader(data_folder=\"./\",\n",
        "                                source_suffix=\"join\",\n",
        "                                target_suffix=\"spa\",\n",
        "                                split=\"val\",\n",
        "                                tokens_in_batch=tokens_in_batch)\n",
        "\n",
        "    # Initialize model or load checkpoint\n",
        "    if checkpoint is None:\n",
        "        model = Transformer(vocab_size=274,\n",
        "                            positional_encoding=positional_encoding,\n",
        "                            d_model=d_model,\n",
        "                            n_heads=n_heads,\n",
        "                            d_queries=d_queries,\n",
        "                            d_values=d_values,\n",
        "                            d_inner=d_inner,\n",
        "                            n_layers=n_layers,\n",
        "                            dropout=dropout)\n",
        "        optimizer = torch.optim.Adam(params=[p for p in model.parameters() if p.requires_grad],\n",
        "                                     lr=lr,\n",
        "                                     betas=betas,\n",
        "                                     eps=epsilon)\n",
        "\n",
        "    else:\n",
        "        checkpoint = torch.load(checkpoint)\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n",
        "        model = checkpoint['model']\n",
        "        optimizer = checkpoint['optimizer']\n",
        "\n",
        "    # Loss function\n",
        "    criterion = LabelSmoothedCE(eps=label_smoothing)\n",
        "\n",
        "    # Move to default device\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    # Find total epochs to train\n",
        "    epochs = (n_steps // (train_loader.n_batches // batches_per_step)) + 1\n",
        "\n",
        "    # Epochs\n",
        "    for epoch in range(start_epoch, epochs+100):\n",
        "        # Step\n",
        "        step = epoch * train_loader.n_batches // batches_per_step\n",
        "\n",
        "        optimizer.lr = lr\n",
        "        # One epoch's training\n",
        "        train_loader.create_batches()\n",
        "        train(train_loader=train_loader,\n",
        "              model=model,\n",
        "              criterion=criterion,\n",
        "              optimizer=optimizer,\n",
        "              epoch=epoch,\n",
        "              step=step)\n",
        "\n",
        "        # One epoch's validation\n",
        "        val_loader.create_batches()\n",
        "        validate(val_loader=val_loader,\n",
        "                 model=model,\n",
        "                 criterion=criterion)\n",
        "\n",
        "        # Save checkpoint\n",
        "        save_checkpoint(epoch, model, optimizer)\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch, step):\n",
        "    \"\"\"\n",
        "    One epoch's training.\n",
        "\n",
        "    :param train_loader: loader for training data\n",
        "    :param model: model\n",
        "    :param criterion: label-smoothed cross-entropy loss\n",
        "    :param optimizer: optimizer\n",
        "    :param epoch: epoch number\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    # Track some metrics\n",
        "    data_time = AverageMeter()  # data loading time\n",
        "    step_time = AverageMeter()  # forward prop. + back prop. time\n",
        "    losses = AverageMeter()  # loss\n",
        "\n",
        "    # Starting time\n",
        "    start_data_time = time.time()\n",
        "    start_step_time = time.time()\n",
        "\n",
        "    # Batches\n",
        "    for i, (source_sequences, target_sequences, source_sequence_lengths, target_sequence_lengths) in enumerate(\n",
        "            train_loader):\n",
        "\n",
        "        # Move to default device\n",
        "        source_sequences = source_sequences.to(device)  # (N, max_source_sequence_pad_length_this_batch)\n",
        "        target_sequences = target_sequences.to(device)  # (N, max_target_sequence_pad_length_this_batch)\n",
        "        source_sequence_lengths = source_sequence_lengths.to(device)  # (N)\n",
        "        target_sequence_lengths = target_sequence_lengths.to(device)  # (N)\n",
        "\n",
        "        # Time taken to load data\n",
        "        data_time.update(time.time() - start_data_time)\n",
        "\n",
        "        try:\n",
        "          # Forward prop.\n",
        "          predicted_sequences = model(source_sequences, target_sequences, source_sequence_lengths,\n",
        "                                      target_sequence_lengths)  # (N, max_target_sequence_pad_length_this_batch, vocab_size)\n",
        "        except:\n",
        "          predicted_sequences = source_sequences\n",
        "          raise Exception(\"Source Sequence: \", list(source_sequences))\n",
        "\n",
        "        # Note: If the target sequence is \"<BOS> w1 w2 ... wN <EOS> <PAD> <PAD> <PAD> <PAD> ...\"\n",
        "        # we should consider only \"w1 w2 ... wN <EOS>\" as <BOS> is not predicted\n",
        "        # Therefore, pads start after (length - 1) positions\n",
        "        loss = criterion(inputs=predicted_sequences,\n",
        "                         targets=target_sequences[:, 1:],\n",
        "                         lengths=target_sequence_lengths - 1)  # scalar\n",
        "\n",
        "        if loss == torch.nan:\n",
        "          print(\"Source Sequence: \", list(source_sequences))\n",
        "          print(\"Target Sequence: \", list(target_sequences))\n",
        "          raise Exception(\"Source Sequence: \", list(source_sequences))\n",
        "        # Backward prop.\n",
        "        (loss / batches_per_step).backward()\n",
        "\n",
        "        # Keep track of losses\n",
        "        losses.update(loss.item(), (target_sequence_lengths - 1).sum().item())\n",
        "\n",
        "        # Update model (i.e. perform a training step) only after gradients are accumulated from batches_per_step batches\n",
        "        if (i + 1) % batches_per_step == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This step is now complete\n",
        "            step += 1\n",
        "\n",
        "            # Update learning rate after each step\n",
        "            change_lr(optimizer, new_lr=get_lr(step=step, d_model=d_model, warmup_steps=warmup_steps))\n",
        "\n",
        "            # Time taken for this training step\n",
        "            step_time.update(time.time() - start_step_time)\n",
        "\n",
        "            # Print status\n",
        "            if step % print_frequency == 0:\n",
        "                print('Epoch {0}/{1}-----'\n",
        "                      'Batch {2}/{3}-----'\n",
        "                      'Step {4}/{5}-----'\n",
        "                      'Data Time {data_time.val:.3f} ({data_time.avg:.3f})-----'\n",
        "                      'Step Time {step_time.val:.3f} ({step_time.avg:.3f})-----'\n",
        "                      'Loss {losses.val:.4f} ({losses.avg:.4f})'.format(epoch + 1, epochs,\n",
        "                                                                        i + 1, train_loader.n_batches,\n",
        "                                                                        step, n_steps,\n",
        "                                                                        step_time=step_time,\n",
        "                                                                        data_time=data_time,\n",
        "                                                                        losses=losses))\n",
        "\n",
        "            # Reset step time\n",
        "            start_step_time = time.time()\n",
        "\n",
        "            # If this is the last one or two epochs, save checkpoints at regular intervals for averaging\n",
        "            if epoch in [epochs - 1, epochs - 2] and step % 1500 == 0:  # 'epoch' is 0-indexed\n",
        "                save_checkpoint(epoch, model, optimizer, prefix='step' + str(step) + \"_\")\n",
        "\n",
        "        # Reset data time\n",
        "        start_data_time = time.time()\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    \"\"\"\n",
        "    One epoch's validation.\n",
        "\n",
        "    :param val_loader: loader for validation data\n",
        "    :param model: model\n",
        "    :param criterion: label-smoothed cross-entropy loss\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        losses = AverageMeter()\n",
        "        # Batches\n",
        "        for i, (source_sequence, target_sequence, source_sequence_length, target_sequence_length) in enumerate(\n",
        "                tqdm(val_loader, total=val_loader.n_batches)):\n",
        "            source_sequence = source_sequence.to(device)  # (1, source_sequence_length)\n",
        "            target_sequence = target_sequence.to(device)  # (1, target_sequence_length)\n",
        "            source_sequence_length = source_sequence_length.to(device)  # (1)\n",
        "            target_sequence_length = target_sequence_length.to(device)  # (1)\n",
        "\n",
        "            # Forward prop.\n",
        "            predicted_sequence = model(source_sequence, target_sequence, source_sequence_length,\n",
        "                                       target_sequence_length)  # (1, target_sequence_length, vocab_size)\n",
        "\n",
        "            # Note: If the target sequence is \"<BOS> w1 w2 ... wN <EOS> <PAD> <PAD> <PAD> <PAD> ...\"\n",
        "            # we should consider only \"w1 w2 ... wN <EOS>\" as <BOS> is not predicted\n",
        "            # Therefore, pads start after (length - 1) position\n",
        "            loss = criterion(inputs=predicted_sequence, targets=target_sequence[:, 1:], lengths=target_sequence_length - 1)\n",
        "\n",
        "            # Keep track of losses\n",
        "            losses.update(loss.item(), (target_sequence_length - 1).sum().item())\n",
        "\n",
        "        print(\"\\nValidation loss: %.3f\\n\\n\" % losses.avg)\n",
        "\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc_Cmg3pOLHw"
      },
      "outputs": [],
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju3z8RuW8kiH"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybokXf4cAciN"
      },
      "outputs": [],
      "source": [
        "from google. colab import runtime\n",
        "runtime. unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj_g4vyz_H3B"
      },
      "source": [
        "Save Model to Google Derive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw9CmceddPRU",
        "outputId": "1b5ae020-8363-4c66-b19b-426f96121635"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import gc\n",
        "# del model\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrLxwgI4JxOs"
      },
      "source": [
        "Translate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8eNs8dg_F9b"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq5ok_YuJzRp"
      },
      "outputs": [],
      "source": [
        "#@title Transform method\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Transformer model\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/MTModel/seq2seq2.pth.tar\")\n",
        "model = checkpoint['model'].to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "def transform(source_sequence, beam_size=4, length_norm_coefficient=0.6):\n",
        "    with torch.no_grad():\n",
        "        # Beam size\n",
        "        k = beam_size\n",
        "        # Minimum number of hypotheses to complete\n",
        "        n_completed_hypotheses = min(k, 10)\n",
        "\n",
        "        # Vocab size\n",
        "        vocab_size = 274\n",
        "\n",
        "        if isinstance(source_sequence, str):\n",
        "            encoder_sequences = encodeString(source_sequence)\n",
        "            encoder_sequences = torch.LongTensor(encoder_sequences).unsqueeze(0)\n",
        "        else:\n",
        "            encoder_sequences = source_sequence\n",
        "        encoder_sequences = encoder_sequences.to(device)  # (1, source_sequence_length)\n",
        "        encoder_sequence_lengths = torch.LongTensor([encoder_sequences.size(1)]).to(device)  # (1)\n",
        "\n",
        "        # Encode\n",
        "        encoder_sequences = model.encoder(encoder_sequences=encoder_sequences,\n",
        "                                          encoder_sequence_lengths=encoder_sequence_lengths)  # (1, source_sequence_length, d_model)\n",
        "\n",
        "        # Our hypothesis to begin with is just <BOS>\n",
        "        hypotheses = torch.LongTensor([[vocabMap['<BOS>']]]).to(device)  # (1, 1)\n",
        "        hypotheses_lengths = torch.LongTensor([hypotheses.size(1)]).to(device)  # (1)\n",
        "\n",
        "        # Tensor to store hypotheses' scores; now it's just 0\n",
        "        hypotheses_scores = torch.zeros(1).to(device)  # (1)\n",
        "\n",
        "        # Lists to store completed hypotheses and their scores\n",
        "        completed_hypotheses = list()\n",
        "        completed_hypotheses_scores = list()\n",
        "\n",
        "        # Start decoding\n",
        "        step = 1\n",
        "\n",
        "        # Assume \"s\" is the number of incomplete hypotheses currently in the bag; a number less than or equal to \"k\"\n",
        "        # At this point, s is 1, because we only have 1 hypothesis to work with, i.e. \"<BOS>\"\n",
        "        while True:\n",
        "            s = hypotheses.size(0)\n",
        "            decoder_sequences = model.decoder(decoder_sequences=hypotheses,\n",
        "                                              decoder_sequence_lengths=hypotheses_lengths,\n",
        "                                              encoder_sequences=encoder_sequences.repeat(s, 1, 1),\n",
        "                                              encoder_sequence_lengths=encoder_sequence_lengths.repeat(\n",
        "                                                  s))  # (s, step, vocab_size)\n",
        "            # Scores at this step\n",
        "            scores = decoder_sequences[:, -1, :]  # (s, vocab_size)\n",
        "            scores = F.log_softmax(scores, dim=-1)  # (s, vocab_size)\n",
        "\n",
        "            # Add hypotheses' scores from last step to scores at this step to get scores for all possible new hypotheses\n",
        "            scores = hypotheses_scores.unsqueeze(1) + scores  # (s, vocab_size)\n",
        "\n",
        "            # Unroll and find top k scores, and their unrolled indices\n",
        "            top_k_hypotheses_scores, unrolled_indices = scores.view(-1).topk(k, 0, True, True)  # (k)\n",
        "\n",
        "            # Convert unrolled indices to actual indices of the scores tensor which yielded the best scores\n",
        "            prev_word_indices = unrolled_indices // vocab_size  # (k)\n",
        "            next_word_indices = unrolled_indices % vocab_size  # (k)\n",
        "\n",
        "            # Construct the the new top k hypotheses from these indices\n",
        "            top_k_hypotheses = torch.cat([hypotheses[prev_word_indices], next_word_indices.unsqueeze(1)],\n",
        "                                         dim=1)  # (k, step + 1)\n",
        "\n",
        "            # Which of these new hypotheses are complete (reached <EOS>)?\n",
        "            complete = next_word_indices == vocabMap['<EOS>']  # (k), bool\n",
        "\n",
        "            # Set aside completed hypotheses and their scores normalized by their lengths\n",
        "            # For the length normalization formula, see\n",
        "            # \"Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\"\n",
        "            completed_hypotheses.extend(top_k_hypotheses[complete].tolist())\n",
        "            norm = math.pow(((5 + step) / (5 + 1)), length_norm_coefficient)\n",
        "            completed_hypotheses_scores.extend((top_k_hypotheses_scores[complete] / norm).tolist())\n",
        "\n",
        "            # Stop if we have completed enough hypotheses\n",
        "            if len(completed_hypotheses) >= n_completed_hypotheses:\n",
        "                break\n",
        "\n",
        "            # Else, continue with incomplete hypotheses\n",
        "            hypotheses = top_k_hypotheses[~complete]  # (s, step + 1)\n",
        "            hypotheses_scores = top_k_hypotheses_scores[~complete]  # (s)\n",
        "            hypotheses_lengths = torch.LongTensor(hypotheses.size(0) * [hypotheses.size(1)]).to(device)  # (s)\n",
        "\n",
        "            # Stop if things have been going on for too long\n",
        "            if step > 100:\n",
        "                break\n",
        "            step += 1\n",
        "\n",
        "        # If there is not a single completed hypothesis, use partial hypotheses\n",
        "        if len(completed_hypotheses) == 0:\n",
        "            completed_hypotheses = hypotheses.tolist()\n",
        "            completed_hypotheses_scores = hypotheses_scores.tolist()\n",
        "\n",
        "        # Decode the hypotheses\n",
        "        all_hypotheses = list()\n",
        "        # for i, h in enumerate():\n",
        "        #     all_hypotheses.append({\"hypothesis\": h, \"score\": completed_hypotheses_scores[i]})\n",
        "\n",
        "        completed_hypotheses_scores=[]\n",
        "        count =0\n",
        "        for hypothesis in completed_hypotheses:\n",
        "          result = decodeString(hypothesis)\n",
        "          completed_hypotheses_scores.append({\"hypothesis\": result, \"index\":count })\n",
        "          count +=1\n",
        "        # Find the best scoring completed hypothesis\n",
        "        best_hypothesis = completed_hypotheses_scores[0][\"hypothesis\"]\n",
        "        # return best_hypothesis, all_hypotheses\n",
        "        return best_hypothesis, completed_hypotheses_scores\n",
        "\n",
        "# selected, results = transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl7GDfUiVGM2"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/NewModel/ASROutputs ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UObiCSBAlQc"
      },
      "outputs": [],
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4wzeDkgbF6x"
      },
      "outputs": [],
      "source": [
        "# !ls -la /content/drive/MyDrive/MTModel/seq2seq_32_epoch_Val_err_0_915.pth.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsrPpwz2Y35o"
      },
      "outputs": [],
      "source": [
        "asentences = []\n",
        "with open(\"/content/ASROutputs/alffa_amharic_test.txt\", \"r\", encoding=\"utf-8\")  as trueValue:\n",
        "  asentences = trueValue.readlines()\n",
        "  count =0\n",
        "  while count < len(asentences):\n",
        "    asentences[count]= asentences[count].strip()\n",
        "    count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlAnV7fyou_W"
      },
      "outputs": [],
      "source": [
        "true_value_list = []\n",
        "with open(\"val.spa\", \"r\", encoding=\"utf-8\")  as trueValue:\n",
        "  true_value_list = trueValue.readlines()\n",
        "  count =0\n",
        "  while count < len(true_value_list):\n",
        "    true_value_list[count]= true_value_list[count].strip()\n",
        "    count+=1\n",
        "\n",
        "def run_test(filename: str):\n",
        "  results = []\n",
        "  # print(result[0]['generated_text'])\n",
        "  with open(filename, \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    if len(lines)  != len(true_value_list):\n",
        "      print(f\"Length difference between test prediction: {len(lines)} and True Values: {len(true_value_list)}\")\n",
        "    for i in range(len(lines)):\n",
        "      result1, result2 = transform(lines[i])\n",
        "      results.append(result1)\n",
        "\n",
        "    filePrediction = open(f\"{filename.split('.')[0]}_predictions.txt\", \"w\", encoding=\"utf-8\")\n",
        "    filePrediction.writelines(results)\n",
        "    filePrediction.close()\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bud7d29Y6BmI"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/character_generated_results.txt .\n",
        "# !cp /content/character_generated_results.txt /content/drive/MyDrive/\n",
        "# !cp /content/character_generated_results.txt /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuL5i_mluPHL"
      },
      "outputs": [],
      "source": [
        "# speechbrain_output = run_test(\"/content/ASROutputs/speechbrain_output.txt\")\n",
        "phonemebased_output = run_test(\"/content/ASROutputs/character_233_amharic_predictions (1).txt\")\n",
        "characterbased_output = run_test(\"/content/ASROutputs/c_37_phoneme_amharic_predictions (2).txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV-0YcJZfOgb",
        "outputId": "78fc8d5d-3d6f-4939-b2f2-327d3a8e40f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "የኢንተርኔት አገልግሎትንም በተመለከተ በክልሎች በዞኖችና በአዲስ አበባ በተለያዩ ቦታዎች የአገልግሎት ማእከሎችን ለማቋቋም መታቀዱን አብራርተዋል\n"
          ]
        }
      ],
      "source": [
        "# print(speechbrain_output[0])\n",
        "print(characterbased_output[0])\n",
        "# print(phonemebased_output[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGatG0-GcbBZ",
        "outputId": "7a1cc925-6132-47bf-8086-dcc71ac67ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.3 rapidfuzz-3.8.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install jiwer\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXf4V_lZb-zK"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, load_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "09d16a4715b7427aae06a5c75b735aff",
            "31cc55d2b2c84deb85d99410686d6d67",
            "5ca475dcf7a846abb2a3519350b61de2",
            "57df1ddb3dab4de7bdf0c5e61677cc2d",
            "812f9612cb21424c8f8c5e4ed1242f2a",
            "0b1e67da80b741daa7699f7e60b93f4e",
            "1fa97fbf4ea148fea2802ee12201798b",
            "942d082ef79b4d9693709f3cc235aa93",
            "8481cdf906784f38990d6c5225a7b480",
            "2411daa8b8b14d1a9e61f19ce09a834f",
            "c823295ac3854150871ce709af9712bb",
            "b3433b00276f45af8dc63a2b512627d9",
            "df48b9d860dc4a0ca1c9c10582ae8213",
            "7d9bcc9cd06c48218b02de868bcb173b",
            "495d07ddfbf24b1fa49b2345e6f9eb8c",
            "1840f2e813ff46ff8bb02ffa545f2692",
            "06da61594e664a03bc4fb0bdfc284969",
            "9bf329e89a8d48b7ab0a46c3a868e3b4",
            "2ee35ca343134929abc00eba7dea101e",
            "644ce3dbeb054290971d5511c2a5856d",
            "c13fef8a31434101bdbb0dbe67d4721b",
            "0741064a10b14130a0ed6356433b42b2"
          ]
        },
        "id": "KvzfiVWiz_ap",
        "outputId": "e853c29a-4d2c-46cd-f52e-889114544745"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-0dc5f81e0ca6>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  wer_metric = load_metric(\"wer\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for wer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/wer/wer.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09d16a4715b7427aae06a5c75b735aff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for cer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/cer/cer.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3433b00276f45af8dc63a2b512627d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wer_metric = load_metric(\"wer\")\n",
        "cer_metric = load_metric(\"cer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLqmmnIWl72Z"
      },
      "outputs": [],
      "source": [
        "!cd /content/gdrive/MyDrive/NewModel/ALFFAAmharic233/train/wav/ && ls -1 | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfY_qx7EmBeS",
        "outputId": "e5762d38-2afe-4e89-f706-506b10b7a6fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: cd: /content/gdrive/MyDrive/NewModel/ALFFAAmharic233/train/wav_old/: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cd /content/gdrive/MyDrive/NewModel/ALFFAAmharic233/train/wav_old/ && ls -1 | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajj_FaPaT4r7"
      },
      "outputs": [],
      "source": [
        "#@title sample result\n",
        "with open(\"now.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "  for a in results:\n",
        "    file.write(a.strip()+ \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSq5dC90DWSj",
        "outputId": "844c9675-49e5-4f4d-f9bf-ec5d2b70c8c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "359"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPtpq20A3-JE",
        "outputId": "c154b21c-3c4f-43a0-e03b-444cfe6168b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test CER: 0.074\n",
            "Test WER: 0.294\n",
            "Compared with ALFFA test dataset\n",
            "Test CER: 0.150\n",
            "Test WER: 0.704\n"
          ]
        }
      ],
      "source": [
        "#@title Speechbrain results\n",
        "\n",
        "print(\"Test CER: {:.3f}\".format(cer_metric.compute(predictions=speechbrain_output, references=true_value_list)))\n",
        "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=speechbrain_output, references=true_value_list)))\n",
        "\n",
        "print(\"Compared with ALFFA test dataset\")\n",
        "print(\"Test CER: {:.3f}\".format(cer_metric.compute(predictions=speechbrain_output, references=asentences)))\n",
        "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=speechbrain_output, references=asentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_slZigDZkzu",
        "outputId": "9231ceef-5d38-4067-c375-fde3e1823f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test CER: 0.070\n",
            "Test WER: 0.273\n",
            "Compared with ALFFA test dataset\n",
            "Test CER: 0.147\n",
            "Test WER: 0.701\n"
          ]
        }
      ],
      "source": [
        "#@title Phoneme Based results\n",
        "\n",
        "print(\"Test CER: {:.3f}\".format(cer_metric.compute(predictions=phonemebased_output, references=true_value_list)))\n",
        "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=phonemebased_output, references=true_value_list)))\n",
        "\n",
        "print(\"Compared with ALFFA test dataset\")\n",
        "print(\"Test CER: {:.3f}\".format(cer_metric.compute(predictions=phonemebased_output, references=asentences)))\n",
        "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=phonemebased_output, references=asentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdjlm9akvkQ6",
        "outputId": "9128ba74-6f9c-4883-ce36-585ee5357548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test CER: 0.071\n",
            "Test WER: 0.278\n",
            "Compared with ALFFA test dataset\n",
            "Test CER: 0.148\n",
            "Test WER: 0.700\n"
          ]
        }
      ],
      "source": [
        "#@title Character Based results\n",
        "\n",
        "print(\"Test CER: {:.3f}\".format(cer_metric.compute(predictions=characterbased_output, references=true_value_list)))\n",
        "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=characterbased_output, references=true_value_list)))\n",
        "\n",
        "print(\"Compared with ALFFA test dataset\")\n",
        "print(\"Test CER: {:.3f}\".format(cer_metric.compute(predictions=characterbased_output, references=asentences)))\n",
        "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=characterbased_output, references=asentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKViOcjsdMkm",
        "outputId": "b76db1b6-9657-4023-e7d4-aaa57f511e2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "359\n"
          ]
        }
      ],
      "source": [
        "# print(len(phonemebased_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCVjhEYIvk9L",
        "outputId": "bc5aad49-369e-4e0c-cabb-40fcbe70c813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test CER: 0.071\n",
            "Test WER: 0.277\n"
          ]
        }
      ],
      "source": [
        "# #@title Phoneme based results\n",
        "# print(\"Test CER: {:.3f}\".format(cer_metric.compute(predictions=phonemebased_output, references=true_value_list)))\n",
        "# print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=phonemebased_output, references=true_value_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0qXVgpI4HZh",
        "outputId": "b5f280f3-e793-463c-e0b8-c076e55c0789"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ሀጂማ አመድ ወሊመልእክት አስተላለፉ',\n",
              " 'ለዚህም ይመስላል ባነሱት ነጥብ ላይ ብዙ ሙረፋ አልበዛባቸው',\n",
              " 'በቅዳሜ የተደረጉት ግጥሚያዎች ለተመርካቹ ቁጥር ዝክተኛመሆን ምክንያት ሆኗል',\n",
              " 'ከዚያም የክልሉ ኮሚሽን ጃር ሜዳ ቢሮ ስለሰጠን ወደዚያው ሄድንኳ',\n",
              " 'ነገር ግን ተጫዋቹን የሚፈልገው ክለቡ እንጂ አሰልጣኝ ጉዴት አልነበርም',\n",
              " 'በትግራይ ህዝብ ስም የተቋቋመው ኤፈርት አዲስ የቴሌቪዥን ጤቢያ ሊከፈት መሆኑን ለጋዜጣዋ ዜና ዴስክ በኢንተርኔት የደረሰው ዘገባ አመለከተች',\n",
              " 'ከዚህም ሌላ የቴሌቪዥኗ ጋዜጠኛ እንግዳዘር ነጋ እቅሯ ኖኦፕራሲዮን የሆኔ ሲሆን አሁን ከኦፕራሲያኑ በኋላ በደና ሁኔታ ትገኛለች ሲል ጠቁሟል',\n",
              " 'ዘታኝም ዘጋቢ እንደ ዘገበው ትልቁ የምግብ ማመላለስ ተግባር ወደ ዲናን የተደረገው ከሀምሳ ቀናት በፊት ነበርኳ',\n",
              " 'ወደከተማ በሚመጡ እንግዶች ላይ ድንጋጤን ይፈጥራል በሚል ችግሩ ባለበት ታፍኖ እንዲያስተደርጓል',\n",
              " 'ዛሬ ሚጽሁፍ እስከ ተጻፈበት ድረስ ከአንድ ሺ ዘጠኝ መቶ አርባ አመተ ምህረት ጀምሮ በዚሁ ከተማ በመኖር ላይ ይገኛሉ']"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "characterbased_output[-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv6y1P45r5YS",
        "outputId": "ff696cc5-9492-4d7e-cef1-10d1b58c6e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test CER: 0.060\n",
            "Test WER: 0.247\n"
          ]
        }
      ],
      "source": [
        "print(\"Test CER: {:.3f}\".format(cer_metric.compute(predictions=results[:201], references=true_value_list)))\n",
        "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=results[:201], references=true_value_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL-LhRN0Mf7M"
      },
      "outputs": [],
      "source": [
        "with open(\"new_one.txt\", \"w\" , encoding=\"utf-8\") as file:\n",
        "  for a in results:\n",
        "    file.write(a+\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYWOrn_XFY7X"
      },
      "outputs": [],
      "source": [
        "dlines = []\n",
        "with open(\"val.join\", \"r\") as file:\n",
        "  dlines = file.readlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfEgb1NaKjOu"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AF2Obar_KlLP"
      },
      "outputs": [],
      "source": [
        "#@title blue score example\n",
        "# Use sacreBLEU in Python or in the command-line?\n",
        "# Using in Python will use the test data downloaded in prepare_data.py\n",
        "# Using in the command-line will use test data automatically downloaded by sacreBLEU...\n",
        "# ...and will print a standard signature which represents the exact BLEU method used! (Important for others to be able to reproduce or compare!)\n",
        "sacrebleu_in_python = True\n",
        "\n",
        "# Make sure the right model checkpoint is selected in translate.py\n",
        "\n",
        "# Data loader\n",
        "test_loader = SequenceLoader(data_folder=\"./\",\n",
        "                             source_suffix=\"en\",\n",
        "                             target_suffix=\"am\",\n",
        "                             split=\"test\", tokens_in_batch=None)\n",
        "test_loader.create_batches()\n",
        "\n",
        "# Evaluate\n",
        "with torch.no_grad():\n",
        "    hypotheses = list()\n",
        "    references = list()\n",
        "    for i, (source_sequence, target_sequence, source_sequence_length, target_sequence_length) in enumerate(\n",
        "            tqdm(test_loader, total=test_loader.n_batches)):\n",
        "        hypotheses.append(translate(source_sequence=source_sequence,\n",
        "                                    beam_size=4,\n",
        "                                    length_norm_coefficient=0.6)[0])\n",
        "        references.extend(test_loader.bpe_model.decode(target_sequence.tolist(), ignore_ids=[0, 2, 3]))\n",
        "    if sacrebleu_in_python:\n",
        "        print(\"\\n13a tokenization, cased:\\n\")\n",
        "        print(sacrebleu.corpus_bleu(hypotheses, [references]))\n",
        "        print(\"\\n13a tokenization, caseless:\\n\")\n",
        "        print(sacrebleu.corpus_bleu(hypotheses, [references], lowercase=True))\n",
        "        print(\"\\nInternational tokenization, cased:\\n\")\n",
        "        print(sacrebleu.corpus_bleu(hypotheses, [references], tokenize='intl'))\n",
        "        print(\"\\nInternational tokenization, caseless:\\n\")\n",
        "        print(sacrebleu.corpus_bleu(hypotheses, [references], tokenize='intl', lowercase=True))\n",
        "        print(\"\\n\")\n",
        "    else:\n",
        "        with codecs.open(\"translated_test.am\", \"w\", encoding=\"utf-8\") as f:\n",
        "          f.write(\"\\n\".join(hypotheses))\n",
        "        print(\"\\n13a tokenization, cased:\\n\")\n",
        "        os.system(\"cat translated_test.am | sacrebleu -t wmt14/full -l en-de\")\n",
        "        print(\"\\n13a tokenization, caseless:\\n\")\n",
        "        os.system(\"cat translated_test.am | sacrebleu -t wmt14/full -l en-de -lc\")\n",
        "        print(\"\\nInternational tokenization, cased:\\n\")\n",
        "        os.system(\"cat translated_test.am | sacrebleu -t wmt14/full -l en-de -tok intl\")\n",
        "        print(\"\\nInternational tokenization, caseless:\\n\")\n",
        "        os.system(\"cat translated_test.am | sacrebleu -t wmt14/full -l en-de -tok intl -lc\")\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-0IA1Tc-rfy"
      },
      "outputs": [],
      "source": [
        "# Reverse map the string\n",
        "phonemeToCharMap = {\"ፕ\": \"ፕ\", \"ህ\": \"ህ\", \"ል\": \"ል\", \"ም\": \"ም\", \"ር\": \"ር\", \"ስ\": \"ስ\", \"ሽ\": \"ሽ\", \"ቅ\": \"ቅ\", \"ብ\": \"ብ\", \"ቭ\": \"ቭ\", \"ት\": \"ት\", \"ች\": \"ች\", \"ን\": \"ን\", \"ኝ\": \"ኝ\", \"ክ\": \"ክ\", \"ው\": \"ው\", \"ዝ\": \"ዝ\", \"ዥ\": \"ዥ\", \"ፍ\": \"ፍ\", \"ጽ\": \"ጽ\", \"ጵ\": \"ጵ\", \"ጭ\": \"ጭ\", \"ጥ\": \"ጥ\", \"ግ\": \"ግ\", \"ጅ\": \"ጅ\", \"ድ\": \"ድ\", \"ይ\": \"ይ\", \"ኣ\": \"አ\", \"ኡ\": \"ኡ\", \"ኢ\": \"ኢ\", \"ኤ\": \"ኤ\", \"እ\": \"እ\", \"ኦ\": \"ኦ\", \"ህኡ\": \"ሁ\", \"ህኢ\": \"ሂ\", \"ህኣ\": \"ሀ\", \"ህኤ\": \"ሄ\", \"ህኦ\": \"ሆ\", \"ልኧ\": \"ለ\", \"ልኡ\": \"ሉ\", \"ልኢ\": \"ሊ\", \"ልኣ\": \"ላ\", \"ልኤ\": \"ሌ\", \"ልኦ\": \"ሎ\", \"ምኧ\": \"መ\", \"ምኡ\": \"ሙ\", \"ምኢ\": \"ሚ\", \"ምኣ\": \"ማ\", \"ምኤ\": \"ሜ\", \"ምኦ\": \"ሞ\", \"ርኧ\": \"ረ\", \"ርኡ\": \"ሩ\", \"ርኢ\": \"ሪ\", \"ርኣ\": \"ራ\", \"ርኤ\": \"ሬ\", \"ርኦ\": \"ሮ\", \"ስኧ\": \"ሰ\", \"ስኡ\": \"ሱ\", \"ስኢ\": \"ሲ\", \"ስኣ\": \"ሳ\", \"ስኤ\": \"ሴ\", \"ስኦ\": \"ሶ\", \"ሽኧ\": \"ሸ\", \"ሽኡ\": \"ሹ\", \"ሽኢ\": \"ሺ\", \"ሽኣ\": \"ሻ\", \"ሽኤ\": \"ሼ\", \"ሽኦ\": \"ሾ\", \"ቅኧ\": \"ቀ\", \"ቅኡ\": \"ቁ\", \"ቅኢ\": \"ቂ\", \"ቅኣ\": \"ቃ\", \"ቅኤ\": \"ቄ\", \"ቅኦ\": \"ቆ\", \"ብኧ\": \"በ\", \"ብኡ\": \"ቡ\", \"ብኢ\": \"ቢ\", \"ብኣ\": \"ባ\", \"ብኤ\": \"ቤ\", \"ብኦ\": \"ቦ\", \"ቭኧ\": \"ቨ\", \"ቭኡ\": \"ቩ\", \"ቭኢ\": \"ቪ\", \"ቭኣ\": \"ቫ\", \"ቭኤ\": \"ቬ\", \"ቭኦ\": \"ቮ\", \"ትኧ\": \"ተ\", \"ትኡ\": \"ቱ\", \"ትኢ\": \"ቲ\", \"ትኣ\": \"ታ\", \"ትኤ\": \"ቴ\", \"ትኦ\": \"ቶ\", \"ችኧ\": \"ቸ\", \"ችኡ\": \"ቹ\", \"ችኢ\": \"ቺ\", \"ችኣ\": \"ቻ\", \"ችኤ\": \"ቼ\", \"ችኦ\": \"ቾ\", \"ንኧ\": \"ነ\", \"ንኡ\": \"ኑ\", \"ንኢ\": \"ኒ\", \"ንኣ\": \"ና\", \"ንኤ\": \"ኔ\", \"ንኦ\": \"ኖ\", \"ኝኧ\": \"ኘ\", \"ኝኡ\": \"ኙ\", \"ኝኢ\": \"ኚ\", \"ኝኣ\": \"ኛ\", \"ኝኤ\": \"ኜ\", \"ኝኦ\": \"ኞ\", \"ክኧ\": \"ከ\", \"ክኡ\": \"ኩ\", \"ክኢ\": \"ኪ\", \"ክኣ\": \"ካ\", \"ክኤ\": \"ኬ\", \"ክኦ\": \"ኮ\", \"ውኧ\": \"ወ\", \"ውኡ\": \"ዉ\", \"ውኢ\": \"ዊ\", \"ውኣ\": \"ዋ\", \"ውኤ\": \"ዌ\", \"ውኦ\": \"ዎ\", \"ዝኧ\": \"ዘ\", \"ዝኡ\": \"ዙ\", \"ዝኢ\": \"ዚ\", \"ዝኣ\": \"ዛ\", \"ዝኤ\": \"ዜ\", \"ዝኦ\": \"ዞ\", \"ዥኧ\": \"ዠ\", \"ዥኡ\": \"ዡ\", \"ዥኢ\": \"ዢ\", \"ዥኣ\": \"ዣ\", \"ዥኤ\": \"ዤ\", \"ዥኦ\": \"ዦ\", \"ይኧ\": \"የ\", \"ይኡ\": \"ዩ\", \"ይኢ\": \"ዪ\", \"ይኣ\": \"ያ\", \"ይኤ\": \"ዬ\", \"ይኦ\": \"ዮ\", \"ድኧ\": \"ደ\", \"ድኡ\": \"ዱ\", \"ድኢ\": \"ዲ\", \"ድኣ\": \"ዳ\", \"ድኤ\": \"ዴ\", \"ድኦ\": \"ዶ\", \"ጅኧ\": \"ጀ\", \"ጅኡ\": \"ጁ\", \"ጅኢ\": \"ጂ\", \"ጅኣ\": \"ጃ\", \"ጅኤ\": \"ጄ\", \"ጅኦ\": \"ጆ\", \"ግኧ\": \"ገ\", \"ግኡ\": \"ጉ\", \"ግኢ\": \"ጊ\", \"ግኣ\": \"ጋ\", \"ግኤ\": \"ጌ\", \"ግኦ\": \"ጐ\", \"ጥኧ\": \"ጠ\", \"ጥኡ\": \"ጡ\", \"ጥኢ\": \"ጢ\", \"ጥኣ\": \"ጣ\", \"ጥኤ\": \"ጤ\", \"ጥኦ\": \"ጦ\", \"ጭኧ\": \"ጨ\", \"ጭኡ\": \"ጩ\", \"ጭኢ\": \"ጪ\", \"ጭኣ\": \"ጫ\", \"ጭኤ\": \"ጬ\", \"ጭኦ\": \"ጮ\", \"ጵኧ\": \"ጰ\", \"ጵኡ\": \"ጱ\", \"ጵኢ\": \"ጲ\", \"ጵኣ\": \"ጳ\", \"ጵኤ\": \"ጴ\", \"ጵኦ\": \"ጶ\", \"ጽኧ\": \"ጸ\", \"ጽኡ\": \"ጹ\", \"ጽኢ\": \"ጺ\", \"ጽኣ\": \"ጻ\", \"ጽኤ\": \"ጼ\", \"ጽኦ\": \"ጾ\", \"ፍኧ\": \"ፈ\", \"ፍኡ\": \"ፉ\", \"ፍኢ\": \"ፊ\", \"ፍኣ\": \"ፋ\", \"ፍኤ\": \"ፌ\", \"ፍኦ\": \"ፎ\", \"ፕኧ\": \"ፐ\", \"ፕኡ\": \"ፑ\", \"ፕኢ\": \"ፒ\", \"ፕኣ\": \"ፓ\", \"ፕኤ\": \"ፔ\", \"ፕኦ\": \"ፖ\", \"ህኡኣ\": \"ኋ\", \"ልኡኣ\": \"ሏ\", \"ምኡኣ\": \"ሟ\", \"ርኡኣ\": \"ሯ\", \"ስኡኣ\": \"ሷ\", \"ሽኡኣ\": \"ሿ\", \"ቅኡኣ\": \"ቋ\", \"ብኡኣ\": \"ቧ\", \"ቭኡኣ\": \"ቯ\", \"ትኡኣ\": \"ቷ\", \"ችኡኣ\": \"ቿ\", \"ንኡኣ\": \"ኗ\", \"ኝኡኣ\": \"ኟ\", \"ክኡኣ\": \"ኳ\", \"ዝኡኣ\": \"ዟ\", \"ዥኡኣ\": \"ዧ\", \"ድኡኣ\": \"ዷ\", \"ጅኡኣ\": \"ጇ\", \"ግኡኣ\": \"ጓ\", \"ጥኡኣ\": \"ጧ\", \"ጭኡኣ\": \"ጯ\", \"ጵኡኣ\": \"ጷ\", \"ጽኡኣ\": \"ጿ\", \"ፍኡኣ\": \"ፏ\", \"ፕኡኣ\": \"ፗ\", \"ግኡኤ\": \"ጔ\", \"ክኡኤ\": \"ኴ\", \"ህኡኤ\": \"ኌ\", \"ቅኡኤ\": \"ቌ\", \"ግኡኢ\": \"ጒ\", \"ክኡኢ\": \"ኲ\", \"ህኡኢ\": \"ኊ\", \"ቅኡኢ\": \"ቊ\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8wzUpY_KP6_"
      },
      "outputs": [],
      "source": [
        "def mapBack(sent:str) -> str:\n",
        "  splitted = sent.split(\" \")\n",
        "  return \"\".join([phonemeToCharMap.get(ph, ph) for ph in splitted])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "oiNZTA1sKTkm",
        "outputId": "6a602dc2-cf29-419a-a248-bebc8d828611"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-8479dd010a33>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ንኧ ግኧ ር ግ ን ችኤ ል ስኢ ልኧ አ ው ርኦ ፕኣ ስኡ ፕኧ ር ክኣ ፕ ክኧ ችኣ ም ፕኢ ይኧ ን ስ ልኢ ግ አ ሽኧ ንኣ ፍኢ ክኧ ርኢ ይኣ ል ምኣ ድ ርኢ ድ ግኣ ር ብኣ ልኧ ብኧ ት ጭኧ ውኣ ትኣ ም ክ ን ይኣ ት ውኧ ድኧ ልኤ ልኣ ቅኧ ን ትኧ ዝኧ ውኣ ው ርኡኣ ል\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mapBack' is not defined"
          ]
        }
      ],
      "source": [
        "sample = \"ንኧ ግኧ ር ግ ን ችኤ ል ስኢ ልኧ አ ው ርኦ ፕኣ ስኡ ፕኧ ር ክኣ ፕ ክኧ ችኣ ም ፕኢ ይኧ ን ስ ልኢ ግ አ ሽኧ ንኣ ፍኢ ክኧ ርኢ ይኣ ል ምኣ ድ ርኢ ድ ግኣ ር ብኣ ልኧ ብኧ ት ጭኧ ውኣ ትኣ ም ክ ን ይኣ ት ውኧ ድኧ ልኤ ልኣ ቅኧ ን ትኧ ዝኧ ውኣ ው ርኡኣ ል\"\n",
        "print(mapBack(sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMbxQqF0KUYA"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "with open(\"selected_prediction.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  results = [mapBack(sent) for sent in file.readlines()]\n",
        "final_testing = open(\"final_testing.txt\", \"r\", encoding =\"utf-8\")\n",
        "true_value= final_testing.readlines()\n",
        "final_testing.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VltNLIwvMQeg"
      },
      "outputs": [],
      "source": [
        "new_results = []\n",
        "for r in results:\n",
        "  selected, detail = transform(r.strip())\n",
        "  new_results.append(selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0PkV2p5O-Er"
      },
      "outputs": [],
      "source": [
        "with open(\"newone.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "  for a in new_results:\n",
        "    file.write(a+\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DXHy-FIMVQ1"
      },
      "outputs": [],
      "source": [
        "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=new_results, references=true_value)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SySQEpbFWEVM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\"input\": np.array(results),\"output\": np.array(new_results)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD_ICwQdNa0t",
        "outputId": "240f71db-6121-478a-e226-09a179563256"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['የኢንተርኔት አገልግሎትንም በተመለከተ በክልሎች በዞኖችና በአዲስ አበባ በተለያዩ ቦታዎች የአገልግሎት ማእከሎችን ለማቋቋም መታቀዱን አብራርተዋል\\n',\n",
              " 'በዚህም አነስተኛ መስኖዎችን በማስፋፋት አገሪቱን በተደጋጋሚ ከሚያጠቃት ድርቅና የምግብ እህል እጥረት ለማቃለል እንደሚቻል ጠቁመዋል\\n',\n",
              " 'ይህ እንዳይሆን በህይወታቸው መስዋእትነት ያስገኙትን የኢትዮጵያዊነት ክብር አንግበን ለቅድስት ሀገራችን አንድነትና ሉአላዊነት ሰላምና ብልጽግና በህብረት እንቁም\\n',\n",
              " 'የመጀመሪያው ነጥብ በተቃዋሚ ሀይሎች ሰፈር በጋራ አቋም ላይ በጋራ ለማቆም ያየነው ጽናት አነስተኛ መሆኑ ነው\\n',\n",
              " 'አቅም በሚፈቅደው መሰረት አስቀድሞ መዘጋጀት ስለሚፈልጉ የሚያጠራጥር አይሆንም ስትል የአሜሪካ ድምጽ ዜና ዘጋቢ ገልጻለች\\n',\n",
              " 'ከለቀስተኞቹ መካከል አብዛኛዎቹ ጸሀዩ ዛሬ ተገለጠ ሀይለስላሴ ማሩን አለማችን አባታችን የአፍሪካ አባት የአለም አባት በማለት ነበር ሀዘናቸውን የሚገልጹ\\n',\n",
              " 'ከዚህ ጋር ለሰብአዊ አገልግሎት መሰለፏም ውጤታማ መሆኗም አድናቆትን አትርፎላታል\\n',\n",
              " 'የኮሚሽኑ ውሳኔና የቤተ ክህነቱ ተቃውሞ\\n',\n",
              " 'ይህንንም ባድመንና ሽራሮን በመውረር እውን አርጓል\\n',\n",
              " 'ጋዜጠኞችን መለያየታቸው ብዙዎችን አሳዝኗል\\n',\n",
              " 'ባለፈው ሰኞ እለት ደግሞ በቴሌቭዥን ሌላ ሽልማት ሲሸለም ተመልከትኩ\\n',\n",
              " 'አጠቃላይ ወጪው አስራ ስምንት ሺ ዶላር እንደሆነ ለማወቅ ተችሏል\\n',\n",
              " 'ሌሎቹ በሙሉ ጤነኞች ናቸው\\n',\n",
              " 'መለስና ኢሳያስ እርስ በእርስ ለመገለባበጥ እየሞከሩ ነው\\n',\n",
              " 'የአየር ሀይላችን አውሮፕላኖችም ግዳጃቸውን በተገቢው ፈጽመው በሰላም ተመልሰዋል ሲል የመንግስት ቃል አቀባይ ጽፈት ቤት መግለጫ አስታውቋል\\n',\n",
              " 'ከሟቾቹ ጋር የነበሩ ሁለት ታጣቂዎች በሰላም እጃቸውን መስጠታቸውንም የፖሊስ መግለጫው አክሎ ገልጿል\\n',\n",
              " 'ችግሮቹን ደግሞ ማስወገድ ነበረባቸው\\n',\n",
              " 'አጋፋሪዎቻቸው ባአዳኑም አቋማቸው ለነርሱ ሀርቶናሙ ቡቶ ከሰጡት ድጋፍ አይለይም\\n',\n",
              " 'ይሄኔ መለስ ነቃ አለ\\n',\n",
              " 'በዚህ ክልል ለበርካታ ዜጐችም የስራ እድል ይፈጥራል የሚሉ ሲኖሩ በተለይ ለሶማሊያውያን እድሉ ሰፊ እንደሆነ ተጠቅሷል\\n',\n",
              " 'ድፍረት ባይሆንብኝ ስህተት ነው\\n',\n",
              " 'በሀገራችን የቅርብ ዘመን ታሪክ ውስጥ አራት አዲስ ምእራፍ ከፋች ሁነቶች መጥቀስ ይቻላል\\n',\n",
              " 'የቢራው ኢንዱስትሪ ግን የታክስ ቅነሳ ቢደረግ ለትም ምንም አይነት የዋጋ ለውጥ ለደንበኞቹ አላደረገም\\n',\n",
              " 'ህወሀት ኢህአዴግ ታድሻለሁ ከማለቱና ቀውሱ ከመፈጠሩ በፊት ፖሊስ በፍትህ ሚኒስቴር ስር እንደ ነበር ሲታወቅ ፍትህ ሚኒስትሩም የህወሀት ሰው እንዳልነበሩ ይታውሳል\\n',\n",
              " 'አሁን ለምን ድምጻቸው ጠፋ ሁለቱ አገሮች በጀመሩት ጦርነት የበለጠ የሰጋው የአሜሪካ መንግስት ነው\\n',\n",
              " 'ሁሴን አይዲድ በአሊትሀድ ላይ አቋም ወሰዱ ስምምነትም አደረጉ\\n',\n",
              " 'በዚህ እንደ ተስማሙ ለማን ትሰጥ ለማን ሲባል ለዚህማ ካሳ አለ አይደል አንዴ የኮሶ ሻጭ ልጅ የሚል ሀሳብ ተሰማ\\n',\n",
              " 'ሮናልዶ መናገር የፈለገው ግን ህመሙ ሙሉ ለሙሉ ለመዳን ጊዜ የሚፈልግ ግን የሚድን ለማለት ነበር\\n',\n",
              " 'በአስተያየቱ ትስማማለህ ተብሎ ሲጠየቅ አሰልጣኝ ሀጐስ ይህ አይነት አጋጣሚ በመላው አለም ላይ ሲከሰት ተስተውሏል በማለት መልሷል\\n',\n",
              " 'አኔልካ ከሺ ማይክል ጋር በተደጋጋሚ ተገናኝቶ ያባከናቸው ኳሶች የሚያስቆጩ ናቸው\\n',\n",
              " 'በጀርመን የሚገኙ ወጣቶችም ለብሄራዊ ቡድን እድል ስለማይሰጣቸው ዜግነታቸውን እየለወጡ ይገኛሉ\\n',\n",
              " 'አቶ አለማየሁ ዘገየ በጸረ ሙስና ኮሚሽን ክስ ላይ መካተታቸውን ከጋዜጦች ላይ ከማንበባቸው ውጭ የፍርድ ቤት መጥሪያ እንዳልደረሳችው መናገራቸውም ተጠቁሟል\\n',\n",
              " 'ከኢትዮጵያ ጋር ብንቀላቀል ብዙ የሚለወጥ ነገር የለም\\n',\n",
              " 'የአንግሎ ኢትዮጵያን ማህበር ኤርትራ ሰራዊቷን እንድታስወጣ ጠየቀ\\n',\n",
              " 'እኔ ራሴ የት ቦታ ሆኜ ስራዬን እንደም ሰራ አላውቅም ማለታቸውን ከቢቢሲ በሚተላለፈው ፎከስ ኦን አፍሪካ ፕሮግራም ላይ አስደምጧል\\n',\n",
              " 'የሀገር አስተዳደር ሚኒስትሩ ልዩ ረዳት በመሆን ካገለገሉ በኋላ በቴህራንና በቴልአቪቭ የጀርመን ኤምባሲዎች ውስጥ ተመድበው አገልግለዋል\\n',\n",
              " 'በአቶ መለስ የተጠራው ይህ የጦር ጄኔራሎች ስብሰባ አሁንም እንደ ቀጠለ ነው ተብሏል\\n',\n",
              " 'ባሊዶግሌ የኢትዮጵያ ጦር ተቆጣጥሮታል የተባለው የአይሮፕላን ማረፊያ የሚገኝበት ከተማ ነው\\n',\n",
              " 'ሻእቢያ አከሸፍኳቸው የሚላቸው ስምንቱ የደርግ የዘመቻ ዙሮች መና ሆነው የቀሩት በወያኔ ተዋጊዎች መስዋእትነት እንደሆነ ይነገራል\\n',\n",
              " 'በኤርትራ በኩል በተመሳሳይ መልኩ የተወሰኑ አላማዎች መነደፋቸውን እሙን ነው\\n',\n",
              " 'የአልበሽር መንግስት ከዚህ በኋላ የኤርትራ ሉአላዊነት የሚጻረርና የባለ ስልጣናቱን ስብእና ከሚነካ ተግባር መቆጠብ እንደሚኖርበት ገልጸዋል\\n',\n",
              " 'ይህ ሰው ውሀ ልማት አካባቢ በሚገኘው መኖሪያ ቤቱ የታሸገበት ሲሆን እርሱም የደረሰበት አይታወቅ\\n',\n",
              " 'እኛም ወስፋት ይሆናል እያልን በኋላ በኋላ ነው ይህ የወጣለት\\n',\n",
              " 'ከቁልቢ ወደ ሀረር ተወስደው መታሰራቸው ከመታወቁ በስተቀር ይህ ዜና እስከ ተጠናከረበት ጊዜ ድረስ ምንም አይነት ለውጥ አለመኖሩን ውስጥ አዋቂዎቹ ገልጸዋል\\n',\n",
              " 'በመሆኑም ሌሎች ክልሎችም ከዚህ በመማር ዜጐቻቸውን ከአደገኛ እጾች ለመከላከል በየበኩላቸው ህግና ደንብ ሊያዘጋጁ እንደሚገባ መግፋትና መገፋፋት ተገቢ ይመስላል\\n',\n",
              " 'ስለዚህ አሰልጣኙ ራሳቸውን ብቻ እያዳመጡ ከፍላጐታቸው አልነቃነቅ ብለዋል በማለት አርሴናል ከቻምፒየንስ ሊግ ከወጣ በኋላ የእንግሊዝ የስፖርት ጋዜጠኞች እየጻፉ ነው\\n',\n",
              " 'አሁንም በየክልሉ እየተዘዋወሩ ፕሮጀክቱን እየገመገሙ ናቸው\\n',\n",
              " 'መብራት ሀይል በውሳኔው ተጠቃሚ ሳይሆን እንደማይቀር ከዜና ምንጮቻችን ለመረዳት ችለናል\\n',\n",
              " 'በአውሮፓ መድረክ ላይ በጥሎ ማለፍ ዋንጫው ላይ ለሩብ ፍጻሜ ማለፉን አረጋግጧል\\n',\n",
              " 'በላይኛው በር ሄድን ስንጠይቅምንም አናውቅም ሂዱ ከዚህ ብለውናል\\n',\n",
              " 'ባለፈው ቅዳሜ ፕሬዝዳንት ኢሳያስ በተገኙበት የተማረከውን አብራሪ ኤርትራ ለህዝቧ በማሳየት ህዝብ ለማስደሰት ሙከራ ማድረጓን የተለያዩ የዜና ምንጮች አሳውቀዋል\\n',\n",
              " 'ሸምጋይ ቡድኑ እንደሚሰበሰብ ያስታወቁት የወቅቱ የአፍሪካ አንድነት ድርጅት ሊቀመንበርና የቡርኪናፋሶ ፕሬዝዳንት የሆኑት ብሌዝ ካምፓ ኦሬ ናቸው\\n',\n",
              " 'ፋና ዲሞክራሲ የተሰኘውና የእፎይታ ጋዜጣና መጽሄት አሳታሚ ድርጅት በይፋ ተዘግቶ ሰራተኞች መበተናቸው ታወቀ\\n',\n",
              " 'ለግንዛቤ ያህል አንድ ሄክታር መቶ ሜትር በመቶ ሜትር ወይንም አንድ የኳስ መጫወቻ ሜዳ ያህላል\\n',\n",
              " 'በጉባኤው ላይ የነበሩት የኢነጋማ ፕሬዚዳንት አቶ ክፍሌ ሙላት ግን ጽድቁ ቀርቶ በወጉ በኮነነኝ ነው ያሉት\\n',\n",
              " 'የኬንያው ፕሬዝዳንት ከኢትዮጵያ ባለስልጣናት ጋር በኬንያና በኢትዮጵያ ድንበር ሞያሌ አካባቢ በተነሳው ግጭት እንደ መከሩ ዲፕሎማቲክ ምንጮች ጠቁመዋል\\n',\n",
              " 'ነገር ግን አንድ ቀን ራሱን በቻለ ሂደትና መልክ ሊከናወን የሚችል የማይቀር ድርጊት ነው\\n',\n",
              " 'ኢትዮጵያ በአለም ቀይ መስቀል ፊት ለፊት በግልጽ ለደህንነቷ የሚያሰጉ ኤርትራውያንን ለማባረር ተገዳለች\\n',\n",
              " 'ልኡኩ ከአንድ ወር በኋላ አዲስአባና አስመራ ይገባል ተብሎ ይጠበቃል\\n',\n",
              " 'የሟች ቤተሰቦች መርዶው እስከ አሁን የተደበቀብን አቅም የላቸውም ምን ያደርጋሉ ከሚል ንቀት የመነጨ እንደሆነም በማማረር ይናገራሉ\\n',\n",
              " 'አሁን ጊዜው አይደለም ያላለኝ ሰው የለም ነበር\\n',\n",
              " 'ከዚህም ሌላ ሆስፒታሉ አምስት ፐርሰንት የተጐዳ ሲሆን መገልገያ መሳሪያዎቹ በሙሉ ከጥቅም ውጪ መሆናቸውን የድርጅቱ ሀላፊ ከኖርዌይ ለቢቢሲ ገልጠዋል\\n',\n",
              " 'ትኩረት ሊሰጠው እንደሚገባ እየገለጽን አስፈላጊው መልእክት በቀጥታ የሚመለከታቸውን ሁሉ በመወያየት ተጨማሪ መልእክት ለማስተላለፍ እንደምንችል ተስፋ እናደጋለን\\n',\n",
              " 'አለበለዚያ ግን ከመሪዎቹ እየራቀ ነው\\n',\n",
              " 'ክለባችን የተመሰረተው በአንድ ሺ ዘጠኝ መቶ ዘጠና ነበር\\n',\n",
              " 'እስካሁን ያስመዘገበው ውጤትም የሚያበረታታ ነው\\n',\n",
              " 'የብራዚል ሻምፒዮና ልክ እንደ በፊቱ የኢትዮጵያ ሻምፒዮና ውድድር አይነት መንገድ ነው የሚከተለው\\n',\n",
              " 'በግል ትምህርት ተቋማት የሚያስተምሩ የዩኒቨርስቲ መምህራን መንግስት ደመወዝ ከሚከፍላቸው ስራ ውጪ በሌላ የትምህርት ተቋማት እንዳያስተምሩ የሚያግድ አዲስ ደንብ አዘጋጅቷል\\n',\n",
              " 'የቀሯትን መንትያ ልጆች በትካዜ ተመለከተቻቸው እነሱንም እንደምትቀብር ከአይኗ ላይ ከሚነበበው ተስፋ መቁረጥ መረዳት ይቻላል\\n',\n",
              " 'ሌላው የግምገማው እርሰ ጉዳይ ሆኖ የቀረበው አሰራር ዘለል የሚባለው ነው\\n',\n",
              " 'እንዲያውም ከሌላው አልተማረም ከሚባለው የህብረተሰብ ክፍል ባነሰ መጠን እራሱን ከትግሉ አርቆ ነው የሚገኘው\\n',\n",
              " 'ባልተለመደ ሁኔታም ለብዙዎቹ የነዳጅ ቦቴዎች ተሰናክሎ በየገራዡና በየቤቱ መኮልኮልም ዋናው መንስኤ ይአው መሆኑ በስፋት እየተነገረ ነው\\n',\n",
              " 'ኢትዮጵያ ወደቡን በነጻ የምትጠቀምበት ሁኔታ ይመቻቻል ተባለ\\n',\n",
              " 'በዶክተር ታዬ ወልደሰማያት ላይ የሚሰማው ውሳኔ በዳኛው አለመገኘት ተራዘመ\\n',\n",
              " 'በዴንቨር ኮሎራዶ አሜሪካ በቅርቡ በተካሄደው በኢንዱስትሪ እድገት በመጠቁ የስምንት አገሮች ስብሰባ ላይ የተወሰነውም ከዚህ ውጭ አልነበረም\\n',\n",
              " 'ያንን የመሰለ ጥያቄ አንስቶ በማሾፍና በማጣጣል ማለፍ ከባድ ነው\\n',\n",
              " 'እነዚህ ከብዙዎቹ የጾም ደረጃዎች ጥቂቶቹ ሲሆኑ በጨዋታና ያለቁምነገር ሌሊቱን ሙሉ በማምሸትና ረመዳን በመምጣቱ የምንጨነቅና የሚከብደን መሆን የለበትም\\n',\n",
              " 'ፕሬዝዳንት ኢሳያስ አፈወርቂ መንግስታቸው ኢህአፓንና ኦነግን ይረዳ ል በሚል ለቀረበላቸው ጥያቄ ኢህአፓንም ሆነ ኦነግን መንግስታቸው እንደማይ ረዳ ገልጸዋል\\n',\n",
              " 'ቤተ ክርስቲያኒቱም ሀገሪቱም አንድ ታላቅ ሰው አጡ\\n',\n",
              " 'ከዚህም ሌላ ባልተረጋገጠ ምንጭ በቀረበ ዜና ከፈረንሳይ ጋግል የተባሉ ሄሊኮኘተሮችና ሌሎችም ተዋጊ አውሮኘላኖች ጂቡቲ መግባታቸው ታውቋል\\n',\n",
              " 'ለአላህ መገዛት ማለት እንዲሁ በቀን አምስቴ ከፊቱ መደፋት ማለት አይደለም ለህግጋቶቹና ትእዛዛቱ ምን ጊዜም ታዛዥ ሆኖ መገኘት ማለት ነው እንጂ\\n',\n",
              " 'ላዚዮዎች እያየሉ በመምጣት የቺሊው ሳላስ ኳስ ይዞ ሲገባ በመጠለፉ የተሰጠውን ፔናልቲ ራሱ በማስቆጠር ላዚዮ ሶስት ለአንድ መምራት ጀመረ\\n',\n",
              " 'ላዚዮና ሚላንስ እንዴት ተዘነጉ ይሄ የእኛ ሀሳብ ነው\\n',\n",
              " 'ከዚህም በተጨማሪ ወጣት ተጨዋቾችን በማሰባሰብ ለወደፊቱ ሊጠናከሩበት የሚችሉበትን መንገድ አመቻችቷል\\n',\n",
              " 'ይህን ጉዳይ አስመልክቶ በተገመገሙበት ወቅት ከሰራተኞቹ ጥያቄ ቀርቦላቸው ሲመልሱ ገንዘቡ እንዲሰጠኝ እኔ ጥያቄ አላቀረብኩም ብለዋል\\n',\n",
              " 'ድንበራችን አሰብ ድረስ ነው እኛ የአንድነት ደቀ መዛሙርት ነን\\n',\n",
              " 'የምድር ባቡር ድርጅት መንገደኞችን የማጓጓዝ አገልግሎት ካለፈው ሁለት ሳምንት ጀምሮ መቋረጡ ታወቀ\\n',\n",
              " 'ሚኒስትሯ የቢሮውን የመድሀኒት ስርጭት ሀላፊ ማነጋገራቸውን ጠቅሶ ግለሰቡ ሀኪም አለመሆኑንና የህክምና እውቀት እንደሌለ ውም አስረድ ቷቸዋል በማለት አ ስፍሯል\\n',\n",
              " 'ሱዳንና ኢትዮጵያ በድንበር ጉዳዮች ዙሪያ ተነጋገሩ\\n',\n",
              " 'እሱም ራሱ ችግር አለበት\\n',\n",
              " 'ከመጋረጃ ጀርባ ወንጀል ተፈጽሟል የሚል ነገር የለም\\n',\n",
              " 'ሌሎቹ ደግሞ በአለም አቀፍ ህብረተሰብ ዘንድ የተለየ መልክና ተቀባይነትን ለማግኘት የተነገረ እንደሆነ ይናገራሉ\\n',\n",
              " 'ህዝቡም እንደለመደው እንዳይነጋገር ወደ ተግባራዊ ውሳኔው እንዳያዘነብል መንገዱን አጠርንበት\\n',\n",
              " 'ከዚያ እስከ ዛሬ ድረስ አቶ አብርሀም ያሉበትን ትግልና እየከፈሉ ያሉትንም መስዋእትነት አውቃለሁ አደንቃለሁም\\n',\n",
              " 'ይህ በእንዲህ እንዳለ አዲስአባ ውስጥ የጨው ዋጋ ንሮ ይገኝ እንጂ በሌሎች ምርቶች ላይ የዋጋ ለውጥ አልታየም\\n',\n",
              " 'ተፈናቃዮች ወደ የክልላችሁ ግቡ ተባሉ\\n',\n",
              " 'ጅቡም ወጣቷን ተከታትሎ ይበላታል ማለት ነው ይስማታል\\n',\n",
              " 'በአሁኑም ወቅት ሁለቱም ወገኖች አልፎ አልፎ በአካባቢው የተኩስ ልውውጥ እያደረጉ መሆኑ ታውቋል\\n',\n",
              " 'የዚህ ባንድ ታሪክ እንደሚ ያስረዳው ከሆነ በዘመናቸው አቻ ያልተገኘላቸው የሮክ ባንድ ተብለዋል\\n',\n",
              " 'ክለቦቹ ግን በተጫወቱበት ወቅት ከቴሌቭዥን በየጨዋታው ስድስት መቶ ሺ ብር ገቢ ያገኛሉ\\n',\n",
              " 'ፍላሚንጐ ባለፈው ቅዳሜ ያስተናገደው በሪዮ ማራካኛ ስቴዲዮም ውስጥ አትሌቲኮ ሚኔይሮን ነበር\\n',\n",
              " 'በስፖንሰር ከተገኘ ገቢ ነው እንጂ\\n',\n",
              " 'በኢንተርናሽናል ግጥሚያ ቡና ና ከነማ አሳምነው ሲያሸንፉ ጊዮርጊስ በቪታሎ ተሸነፈ\\n',\n",
              " 'ውስጣዊ አንድነቱ ዲሲፕሊኑ የስራ ዝግጁነቱ ወደሚፈልገው ደረጃ መድረስ መቻል አለበት\\n',\n",
              " 'ማንም ዜጋ ማንም ደም ይኑረው ልክ እሱ እንዳለው ወሳኙ አመለካከቱ ነው\\n',\n",
              " 'የኤርትራ ማእከላዊ ባንድ ቦንድ በመሸጥ ኢኮኖሚውን ለማረጋጋት የሚያስችለውን ገቢ ለማሰባስብ እንቅስቃሴ መጀመሩን በቅርቡ የዘገበው ሮይተር የተሰኘው የዜና አውታር ነው\\n',\n",
              " 'በአፋር ከሚያስፈልገው እህል አርባ ስድስት ከመቶ ብቻ ነው የቀረበው\\n',\n",
              " 'አንድ ኢትዮጵያዊ ፕሮፌሰር ደግሞ ረጋ ብለን ስናስበው ጦርነቱን ያስከተለው ሁለቱም መሪዎች የተከተሉት የፖለቲካ መስመር ነው ይላሉ\\n',\n",
              " 'ርእሰ አንቀጹ በመቀጠልም ነጻ ጋዜጦች የረቀቀ ማስፈራሪያና ወከባም ይካሄድባቸዋል\\n',\n",
              " 'አንድ አነስተኛ ጉዳይ ለማስፈጸም በጣም ረጅም ቀጠሮ የሚሰጥ በመሆኑ ባለ ጉዳዮችና ጉዳዮቻቸውን የሚከታተሉላቸው ጠበቃዎች ሲማረሩ ቆይተዋል\\n',\n",
              " 'እዚሁ ሊያደቅቃቸው የሚፈልጋቸውን ሰዎች ካልሆነ በቀር ለጠየቀ ሁሉ ፓስፖርትም ቪዛም ይሰጣል\\n',\n",
              " 'ድሮ ከህዝብ የሚሰበሰበው ግብር ነበር\\n',\n",
              " 'የወለደውን ልጅ ለማስተማር ተስኖታል\\n',\n",
              " 'በዚህ አመት መጨረሻ ሀምሌ ወር ወይንም በሚቀጥለው አመት የመጀመሪያ ወራት እነ ዶክተር ታዬ የመጨረሻ ውሳኔ ያገኛሉ ተብሎ ተገምቷል\\n',\n",
              " 'አመዛኙ እርስ በራሱ ሲጨራረስ ጆሮ ዳባ ልበስ ብሎ ማየት የብልህ መሪዎች አስተሳሰብ ሊሆን አይችልም\\n',\n",
              " 'ለጠቅለይ ሚንስትር መለስ ዜናዊ ያስተላለፉትን ደብዳቤ ሙሉ ቃል ከዚህ ቀጥሎ እና ቀርባለን\\n',\n",
              " 'ማህላውም ሆነ ጋብቻውም ስሜቷን የሚኮረኩራት ፍጥረት ባትሆንም እንዲሁ እያደናገረ ወደ ጫካ ይዟት ገባ\\n',\n",
              " 'ዛሬና ነገ በሀገሮች የውስጥ ውድድር በሳምንቱ አጋማሽ ላይ ደግሞ በአውሮፓ ቻምፒየንስ ሊግ እንዲሁ በጉጉት የሚጠበቁ ጨዋታዎች ይደረጋሉ\\n',\n",
              " 'አሰልጣኙ በእርግጥም ብሄራዊ ቡድኑን ከያዙ ወዲህ ክለቡ እየተሸነፈ ነው\\n',\n",
              " 'የሚመደበው ገንዘብ ተሟልቶ ካለቀ በኋላ የሚከተለውን ችግር ከግምት ውስጥ በማስገባት የተለያዩ ገቢ ማስገኛ ዘዴዎችን መቀየሱ አስፈላጊ ነው\\n',\n",
              " 'የአለም የምግብ ፕሮግራም ብቻውን ወደ ሰላሳ ሺ ቶን እህል መርዳቱ ተገልጿል\\n',\n",
              " 'ዘገባው ከዚህ በተጨማሪ በታዳጊ አገሮች ያለውን የድህነት መጠን በተመለከተ ፍንጮችን ይፋ አድርጓል\\n',\n",
              " 'ይህንን በትክክል የሚያውቁት እነሱ ብቻ ናቸው\\n',\n",
              " 'ሻእቢያ እነዚህን አካባቢዎች ለማግኘት ፈልጐ አለማግኘቱና ማጣቱ ድርብ ሽንፈት ውርደት አግኝቶታል ለማለት ይቻላል\\n',\n",
              " 'ይሄ ባለፉት ጊዜያት ብቻ ሳይሆን አሁንም እየቀጠለ ያለና የሚታይ ጉዳይ ነው\\n',\n",
              " 'ቀሪዎቹ አስፈጻሚው አካል በህግ ከተሰጠው ስልጣን ሳይዘል የሚያከናውናቸው ተግባሮች ይሆናሉ\\n',\n",
              " 'አቶ አባተ ኪሾ ያለመከሰስ መብታቸው መገፈፉን የፌዴራሉ ከፍተኛ ፍርድ ቤት አስታወቀ\\n',\n",
              " 'በልጅነት ዘመናቸው ጊዜ የሙት ልጅ ሆነውም ባገኙት ብልጫ ወደ ኤደንብራ እንግሊዝ በመላክ የመጀመሪያው ተማሪ ነበሩ\\n',\n",
              " 'በዚህም ለአገራቸውና ለአፍሪካ ምን ያህል ይጨነቁ እንደ ነበር ለመገንዘብ ችያለሁ\\n',\n",
              " 'ጦር ሲላክበት በግብጾች ጉያ ይደበቃል\\n',\n",
              " 'የአስመራው አምባሳደር ለኤርትራው ሬድዮ የሰጡት ቃል የዲፕሎማሲያዊ ተልእኮአቸውን ለመፈጸም እንጂ በትክክልም የአዲስ አበባው አምባሳደር የሰጡት መግለጫ ከእውነት ርቆ አይደለም\\n',\n",
              " 'አገሬ የመጣሁ አልመሰለኝም አፓርታይድን አስታወሰኝ\\n',\n",
              " 'ሰራዊቱ ይህ ሳይበቃው አለቆቹ ለውድቀቱ ተጠያቂ ናቸው በመባል መታመሳቸው ከፍተኛ ውጥረትን በጦሩ ውስጥ ያሰፈነ መሆኑም ተመልክቷል\\n',\n",
              " 'አምላክ መልአክትን ሲፈጥር የመልአክት አለቃ ሆኖ የተፈጠረው አሁን ሳጥናኤል የምንለው ከይሲ ነበር\\n',\n",
              " 'ጠንካራው ዩናይትድ እየተነቃነቀ ነው\\n',\n",
              " 'ሊድስ ደግሞ ውድጌት ስሚዝ ፖል ሮቢንሰንና ስቴፈን ማክፊል የተባሉ ወጣቶችን ይዟል\\n',\n",
              " 'ቡድኑ በማጥቃት ላይ የተመረኮዘ ፉትቦል ነው የሚጫወተው\\n',\n",
              " 'ለአንተነህ የጠየቀውን አሟልተን ወደ ክለቡ ብንመልስው በተጨዋቾች መካከል ልዩነት ይፈጠርብናል\\n',\n",
              " 'ጅቡቲ ይህን ለምን እንደ ፈጸመች የጅቡቲ የውጭ ጉዳይ ሚኒስተር ሲናገሩ ለሀገራችን ሰላምና መረጋጋት እርምጃችን ፍትሀዊ ነው ብለዋል\\n',\n",
              " 'በዚህም ኢትዮጵያን የተሻለች ሀገር ለማድረግ በሚደረገው ጥረት የበኩሉን አስተዋጽኦ ያደርጋል ብዬ አምናለሁ\\n',\n",
              " 'የሀዲያ ልማት ማህበር ተፈራ መኬ ምክትሉ ደስታ ዳኜ ዘጠኝና ስድስት አመት ተበይኖባቸዋል ሲል ያው የዜና ዘገባ ጨምሮ ገልጿል\\n',\n",
              " 'ምን ጊዜም የሪፖርተር እና የኤምሲሲ ማህበረሰብ አባላት ለፕሮጀክቶቹ ስኬታማነት ከሀይሌና ከአጋሮቹ ጐን ናቸው\\n',\n",
              " 'እስከ አንድ ሺ ዘጠኝ መቶ ስልሳ ስድስት ድረስ በኢትዮጵያ የነበረው መንግስታዊ ስርአት የሲሶ ስርአት በመባል የሚታወቅ እንደ ነበር ይታወሳል\\n',\n",
              " 'እንደ ተማሪው አቋም ትምህርት ለማስጀመር የደህንነት ዋስትና ተሰጥቶ ሁሉንም ተማሪ ያሳተፈ አጠቃላይ ውይይት መደረግ አለበት\\n',\n",
              " 'ኦነግ ለሁለት ተከፍሎ መስማማት የማይችልበት ደረጃ ላይ መድረሱን የአመራር አባላቱ ገለጹ\\n',\n",
              " 'በነዚህ ጠማሞች ክፉ አሳቢዎች ምክንያት የምናኔ ህይወት የሚገፉበት አለም እስከ መሆን ደርሳለች\\n',\n",
              " 'እንደገና ኢትዮጵያዊ ለመሆን መደራደር የመረጡም አሉ\\n',\n",
              " 'ኮሎኔል መንግስቱ ይህንን ግለት ለአብዮቱ ቢያውሉት ሲሉ እኔ እስከማውቀው በቂ ምክንያት ነበራቸው\\n',\n",
              " 'ለእናንተ ነገርኳችሁ እንጂ እግዚዮ በሉ እያለ ህዝቡ ሲያስለቅስ ምላስ የሚያወጣ ባህታዊ አለ አላልኩም\\n',\n",
              " 'ነገሮችን በጥልቀት መመርመርና ማስረዳት የዘወትር ስራዋ የሆነው ሀያል ብእረኛና በሳል ገጣሚ ፍርማዬ አለሙ የአንዲት ሴት ልጅ እናት ነበረች\\n',\n",
              " 'እንደ በፊቱ በአገሩ ላይ ባይተዋርነቱም ቀርቷል\\n',\n",
              " 'ደግሞም ባሏንና ልጅዋን ከአጀብ መሀል የምትፈልግ ሴት ባሏን ብታገኝ ደስ ብሏት ልጅዋንም ብታገኝ አገላብጣ ስማ በደስታ ታለቅሳለች\\n',\n",
              " 'እነርሱ ከሌሉ ዋጋ የለኝም\\n',\n",
              " 'ዛሬ ከሌይስተር ጋራ ከተጫወተ በኋላ ሳምንት ከቸል ሲየሚያደርገው የቡድኑ ደረጃ የሚያመለክት ይሆናል\\n',\n",
              " 'ክለቡ ዘንድሮ አጀማመሩ ጥሩ ነው\\n',\n",
              " 'ለዚህ ውሳኔ ከካፍ ጠበቅ ያለ እርምጃና ቅጣት ይወሰንብናል የሚል ፍራቻ አለ\\n',\n",
              " 'ከዚያም በአንዳንድ አውሮፕላኖች ላይ የተወሰኑ ብልሽ ቶች ተከስተዋል የሚል ዘገባ እንደ ቀረበ ማኔጅመንቱ አስራ ስምንቱን ቴክኒሺያኖች ሊያሰናብቷቸው እንደበቁተ ዘግቧል\\n',\n",
              " 'ግንኙነታችን ደግሞ ወደ ሞቀ ሁኔታ ተመልሷል ብለዋል አንድ ከፍተኛ የጅቡቲ ባለስልጣን ለኢሪን\\n',\n",
              " 'የክልሉ የስራ ቋንቋ ኦሮምኛ እንዲሆንም ተወስኗል\\n',\n",
              " 'የመን ከኤርትራ ጋራ በደሴቶች ግጭት ስላላት የጠላታችን ጠላት ወዳጃችን ነው በሚል ብንይዛት ሀይል ትሆነናለች በሚል ተስፋ ነው\\n',\n",
              " 'ምርጫው በተጠናቀቀ በሰላሳ ቀናት ውስጥ አዲሱ የከተማው ምክር ቤት ስራውን ይጀምራል\\n',\n",
              " 'እነዚህ ሰዎች ጨርሰው ጅል አደረጉን\\n',\n",
              " 'ድንበር የማካለሉ ውሳኔ በገለልተኛ የድንበር ኮሚሽን አማካኝነት በሚቀጥለው ወር ከሄግ እንደሚገለጽ አመልክቷል\\n',\n",
              " 'በዚህ ውጊያ የኢትዮጵያ ተዋጊ ጄቶች እንዲሁም የውጊያ ሄሊኮፕተሮች መሳተፋቸውንም መግለጫው አመልክቷል\\n',\n",
              " 'በዚህ በሀንቲንግተን የስልጣኔዎች ሰንጠረዥ መሰረት ኢትዮጵያችን የየትኛው ስልጣኔ ክበብ አባል እንደሆነች ማወቁ ባልከፋ\\n',\n",
              " 'ከላይ ስለተገለጸው አዲሱ አይነት የብሄር ጭቆና ክስተትም ግንዛቤ ያላቸው አይመስሉም\\n',\n",
              " 'እንዲህ ያለ ነገር አይወጣኝም\\n',\n",
              " 'ሁለቱ ሀይሎች በቅርብ ርቀት ውስጥ እንደሚገኙም ለማስረዳት የሞከረችው በሻእቢያ ወታደሮች ምሽግ ውስጥ በመሆን የኢትዮጵያ ወታደሮች እንቅስቃሴ ይታያል በማለት ነው\\n',\n",
              " 'በአለም ላይ ያሉ የየአገሩ መረጃዎች ካሏቸው የመረጃ ምንጮች ውስጥ አንዱ የፕሬስ ውጤት ነው\\n',\n",
              " 'በኤርትራና በትግራይ ጉዳይ የቀረበላቸውና የሰጡት መልስ ቀጥሎ ቀርቧል\\n',\n",
              " 'በሙያው ለብዙ ጊዜ ሰርቻለሁ\\n',\n",
              " 'በዚህ ላይ ዊአህ ተደራቢ አጥቂ ሆኖ በመጫወት ላይ በመሆኑ እየተማረረ ነው\\n',\n",
              " 'የአዲስ አበባ ስታዲዮም ተመልካች ቄራ የሚል ቅጽል ስም አውጥቶልሀል\\n',\n",
              " 'ከአቅም በላይ የሆነ ችግር ባይኖር ኖሮ ለማሰልጠን ፍቃደኛ ነበርኩኝ\\n',\n",
              " 'በምን እንደ ታሰሩ የሚያቁት የመዝገብ ቤት ሰራተኞች ናቸው\\n',\n",
              " 'ትላንት ጠበቆቼ መጥተው ስንነጋገር እንግሊዘኛ ስላስገባን እኔ በምሰማው ቋንቋ ካልሆነ አትናገሩም አለ በዚያም ትወጣላችሁ ብለው ጠበቆቼን አስፈራሩዋቸው\\n',\n",
              " 'በሌላ በኩል ስርቆትና መሰል ወንጀሎችን ምክንያት አድርጐ በርካታ የመቀሌ ከተማ ነዋሪዎች በመታፈስ ላይ መሆናቸው ታውቋል\\n',\n",
              " 'አውሮፕላኑ እቃጫኝ ሲሆን በበረራው ላይ ስድስት የአየር መንገድ ሰራተኞችን አሳፍሮ ነበር\\n',\n",
              " 'ከዚያ ውጭ የምንለው አይኖረንም\\n',\n",
              " 'የሶማሊያ መንግስት ሀገሪቱን የአሸባሪዎች መናአሪያ እያደረጋት ነው ተባለ\\n',\n",
              " 'ለማን አቤት ማለት እንደሚቻልም ግራ ገብቶናል በማለት ነጋዴዎቹ ብሶታቸውን ገልጸዋል\\n',\n",
              " 'ጉዳዩን በቅርብ ለምንከታተለው ሰዎች ምንም አስደንጋጭ ይዘት የለውም\\n',\n",
              " 'ይህ ሲሚንቶ ባህር ዳር ላይም የሚሸጠው በስልሳ አምስት ብር ነው\\n',\n",
              " 'ሰላም ለእናንተ ይሁን እድምተኞቼ እኔ አሽሙረኛው ለእናንተ ሰላምና ጤናውን እመኛለሁ\\n',\n",
              " 'ኢትዮጵያ ሰላም ፈላጊ በመምሰል እያደረገች ያለችውን ደባ ለማምከንና ሶስተኛውን ዙር ወረራ ለመደምሰስ ዝግጁ ነን ሲሉም ተደምጠዋል\\n',\n",
              " 'ይህን ሞዳሊቲ ለማስፈጸም ሀላፊነት የተጣለባቸው የአልጀሪያው ፕሬዚዳንትና አዲሱ የአአድ ዋና ጸሀፊ ናቸው\\n',\n",
              " 'ወርቅና ብር ቡናና አህል ጋሞጐፋ አለ በሚል ሽፋን ደብዳቤም እየጻፈ የድብቅ ማህበር አቋቋመ\\n',\n",
              " 'ስዩም ነው የጻፈው ብሎ ጽሁፉን አይቼ የእርሱ አለመሆኑን ስነግረው እኔ የማውቀው ነገር የለም ነው ያለኝ\\n',\n",
              " 'ቡድኑ በእንግሊዝ ካሉት ክለቦች በአካል ብቃቱ በኩል የተዋጣለትና ዲስፕሊንን መርሆ ያደረገ እንደነበር ይነገራል\\n',\n",
              " 'አሁን ባለበት ሁኔታ ከቀጠለ ጭራሹኑ ውድድሩ እንዳይጠፋ ያሰጋል\\n',\n",
              " 'ቡድኑ ባደረጋቸው ሶስት ጨዋታዎች ውስጥ ሁለቱን አቻ ሲወጣ በአንዱ ተሸንፏል\\n',\n",
              " 'የኤድስ በሽታና የሻእቢያ ወረራ ጸረ ልማት ናቸው\\n',\n",
              " 'እንደ ዲፕሎማቱ ከሆነ የሻእቢያ ባለስልጣናት የኢትዮጵያ ጦር አሰብን ለመያዝ ቆርጧል ብለው እራሳቸውን አሳምነዋል\\n',\n",
              " 'ወደ ትውልድ መንደራቸው የሚከዱትን ማደን ቀርቶ ለስምንተኛው ዙር የሳዋ ስልጠና ተመልማይ ለማግኘት መቸገሩ ተዘግቧል\\n',\n",
              " 'የድርጅታችን ህግ አስከባሪ ሀይል ኦዲት ኮሚሽን በነሱ ላይ ፍርዱን ሲያሳርፍ ድሮውንም እያወቁ ኩዴታ ያደረጉ በመሆናቸው ሊቀበሉ አልፈለጉም\\n',\n",
              " 'ስለዚህ ጉዳይ አንድ ባለስልጣን ሲናገሩ መንግስት በውስጥ ቅራኔ ውስጥ ነው በማለት አጋጣሚውንና እድሉን ለመጠቀም ፈልገው ነበር ብለዋል\\n',\n",
              " 'አለዚያ ከጉባኤዎቻቸው ከስብሰባዎቻቸውና ከዲስኩራቸው ለህዝብና ለአገር የተረፈ ነገር አላየንም\\n',\n",
              " 'የድንበር ማካለል ሂደቱን በአፋጣኝ ግቡን እንዲመታ አለም አቀፉ ህበረተሰቡን አስፈላጊውን እገዛ እንዲያደርግ ጥሪ ይቀርባል\\n',\n",
              " 'በተጨማሪም የባንክ ቅርንጫፎች በሌለባቸው አካባቢዎች የብር ለውጡ የሚተገብሩ ሶስት መቶ የሚደርሱ ጊዜያዊ የመለዋወጫ ጣቢያዎች መዘጋጀታቸውን አቶ ዱባለ አስረድተዋል\\n',\n",
              " 'ይህ ደግሞ የአንድ እምነት ተከታይነታቸውን እንጂ የህዝቡ መጠሪያ ሆኖ ሊያገለግል የሚችል ስያሜ እንዳልሆነ ግልጽ ነው\\n',\n",
              " 'መጀመሪያ ነገር ይህንን ህገ መንግስት መቀበል ማለት የወያኔን የፖለቲካ ፕሮግራም መቀበል ማለት ይሆናል']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "true_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM-FhqnkN-6v",
        "outputId": "b3a91501-0e49-4aa1-a244-ceb3663c0d02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for cer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/cer/cer.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test CER: 0.089\n"
          ]
        }
      ],
      "source": [
        "#@title Character Error Rate Metric\n",
        "\n",
        "cerMetric = load_metric(\"cer\")\n",
        "print(\"Test CER: {:.3f}\".format(cerMetric.compute(predictions=results, references=true_value)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AJWI6sfPYQH"
      },
      "outputs": [],
      "source": [
        "output_data = []\n",
        "with open(\"val.join\") as file:\n",
        "  lines = file.readlines()\n",
        "  for a in lines:\n",
        "    output_data.append(a.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHi7FWEeYBHp"
      },
      "outputs": [],
      "source": [
        "correct_data = []\n",
        "with open(\"val.spa\") as file:\n",
        "  lines = file.readlines()\n",
        "  for a in lines:\n",
        "    correct_data.append(a.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gg62pgNPna0",
        "outputId": "45c9198e-1c1b-41ca-da65-42821b977c00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test CER: 0.133\n",
            "Test WER: 0.961\n"
          ]
        }
      ],
      "source": [
        "print(\"Test CER: {:.3f}\".format(cer_metric.compute(predictions=output_data, references=correct_data)))\n",
        "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=output_data, references=correct_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WStCVaWPPvui"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06da61594e664a03bc4fb0bdfc284969": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0741064a10b14130a0ed6356433b42b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09d16a4715b7427aae06a5c75b735aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31cc55d2b2c84deb85d99410686d6d67",
              "IPY_MODEL_5ca475dcf7a846abb2a3519350b61de2",
              "IPY_MODEL_57df1ddb3dab4de7bdf0c5e61677cc2d"
            ],
            "layout": "IPY_MODEL_812f9612cb21424c8f8c5e4ed1242f2a"
          }
        },
        "0b1e67da80b741daa7699f7e60b93f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1840f2e813ff46ff8bb02ffa545f2692": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa97fbf4ea148fea2802ee12201798b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2411daa8b8b14d1a9e61f19ce09a834f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee35ca343134929abc00eba7dea101e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31cc55d2b2c84deb85d99410686d6d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b1e67da80b741daa7699f7e60b93f4e",
            "placeholder": "​",
            "style": "IPY_MODEL_1fa97fbf4ea148fea2802ee12201798b",
            "value": "Downloading builder script: "
          }
        },
        "495d07ddfbf24b1fa49b2345e6f9eb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c13fef8a31434101bdbb0dbe67d4721b",
            "placeholder": "​",
            "style": "IPY_MODEL_0741064a10b14130a0ed6356433b42b2",
            "value": " 5.59k/? [00:00&lt;00:00, 369kB/s]"
          }
        },
        "57df1ddb3dab4de7bdf0c5e61677cc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2411daa8b8b14d1a9e61f19ce09a834f",
            "placeholder": "​",
            "style": "IPY_MODEL_c823295ac3854150871ce709af9712bb",
            "value": " 4.47k/? [00:00&lt;00:00, 289kB/s]"
          }
        },
        "5ca475dcf7a846abb2a3519350b61de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_942d082ef79b4d9693709f3cc235aa93",
            "max": 1900,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8481cdf906784f38990d6c5225a7b480",
            "value": 1900
          }
        },
        "644ce3dbeb054290971d5511c2a5856d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d9bcc9cd06c48218b02de868bcb173b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee35ca343134929abc00eba7dea101e",
            "max": 2159,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_644ce3dbeb054290971d5511c2a5856d",
            "value": 2159
          }
        },
        "812f9612cb21424c8f8c5e4ed1242f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8481cdf906784f38990d6c5225a7b480": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "942d082ef79b4d9693709f3cc235aa93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf329e89a8d48b7ab0a46c3a868e3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3433b00276f45af8dc63a2b512627d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df48b9d860dc4a0ca1c9c10582ae8213",
              "IPY_MODEL_7d9bcc9cd06c48218b02de868bcb173b",
              "IPY_MODEL_495d07ddfbf24b1fa49b2345e6f9eb8c"
            ],
            "layout": "IPY_MODEL_1840f2e813ff46ff8bb02ffa545f2692"
          }
        },
        "c13fef8a31434101bdbb0dbe67d4721b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c823295ac3854150871ce709af9712bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df48b9d860dc4a0ca1c9c10582ae8213": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06da61594e664a03bc4fb0bdfc284969",
            "placeholder": "​",
            "style": "IPY_MODEL_9bf329e89a8d48b7ab0a46c3a868e3b4",
            "value": "Downloading builder script: "
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
